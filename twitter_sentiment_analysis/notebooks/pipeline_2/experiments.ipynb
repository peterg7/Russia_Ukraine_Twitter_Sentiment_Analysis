{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import re\n",
    "import multiprocessing\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plot style\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style(theme='onedork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, recall_score, get_scorer, f1_score,roc_auc_score,precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/petergish/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/petergish/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/petergish/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Prep nltk library\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1517715552302686209</td>\n",
       "      <td>1517634680404598784</td>\n",
       "      <td>2022-04-23 04:02:40 UTC</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>04:02:40</td>\n",
       "      <td>0</td>\n",
       "      <td>870355689545371648</td>\n",
       "      <td>voidbourn</td>\n",
       "      <td>VoidBourn IGG ðŸ‡ºðŸ‡² ðŸ‡·ðŸ‡º</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'El_Was_Taken', 'name': 'Elli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1517715545575297025</td>\n",
       "      <td>1517666965464264706</td>\n",
       "      <td>2022-04-23 04:02:38 UTC</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>04:02:38</td>\n",
       "      <td>0</td>\n",
       "      <td>338911267</td>\n",
       "      <td>applekappa1337</td>\n",
       "      <td>Applegaku</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'fedtanyl', 'name': 'Fed For ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1517715539925561344</td>\n",
       "      <td>1517569434956804103</td>\n",
       "      <td>2022-04-23 04:02:37 UTC</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>04:02:37</td>\n",
       "      <td>0</td>\n",
       "      <td>703180594914570240</td>\n",
       "      <td>mbw955</td>\n",
       "      <td>Mal, just another áž”áŸ’ážšáž†áž¶áŸ†áž„áž áŸ’ážœáž¶ážŸáŸŠáž¸ážŸ amongst many.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'pl4ma', 'name': 'plama', 'id...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1517715531574489094</td>\n",
       "      <td>1517533955959967746</td>\n",
       "      <td>2022-04-23 04:02:35 UTC</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>04:02:35</td>\n",
       "      <td>0</td>\n",
       "      <td>1411455047263670273</td>\n",
       "      <td>shodanette</td>\n",
       "      <td>ShodanðŸ”®|</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'Rimlee18', 'name': 'Rimlee',...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1517715528697143296</td>\n",
       "      <td>1517491994922213379</td>\n",
       "      <td>2022-04-23 04:02:34 UTC</td>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>04:02:34</td>\n",
       "      <td>0</td>\n",
       "      <td>1181952375399092225</td>\n",
       "      <td>chilberg11</td>\n",
       "      <td>Carl Hilberg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'InnaSovsun', 'name': 'Inna S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id               created_at  \\\n",
       "0  1517715552302686209  1517634680404598784  2022-04-23 04:02:40 UTC   \n",
       "1  1517715545575297025  1517666965464264706  2022-04-23 04:02:38 UTC   \n",
       "2  1517715539925561344  1517569434956804103  2022-04-23 04:02:37 UTC   \n",
       "3  1517715531574489094  1517533955959967746  2022-04-23 04:02:35 UTC   \n",
       "4  1517715528697143296  1517491994922213379  2022-04-23 04:02:34 UTC   \n",
       "\n",
       "         date      time  timezone              user_id        username  \\\n",
       "0  2022-04-23  04:02:40         0   870355689545371648       voidbourn   \n",
       "1  2022-04-23  04:02:38         0            338911267  applekappa1337   \n",
       "2  2022-04-23  04:02:37         0   703180594914570240          mbw955   \n",
       "3  2022-04-23  04:02:35         0  1411455047263670273      shodanette   \n",
       "4  2022-04-23  04:02:34         0  1181952375399092225      chilberg11   \n",
       "\n",
       "                                              name place  ... geo source  \\\n",
       "0                              VoidBourn IGG ðŸ‡ºðŸ‡² ðŸ‡·ðŸ‡º   NaN  ... NaN    NaN   \n",
       "1                                        Applegaku   NaN  ... NaN    NaN   \n",
       "2  Mal, just another áž”áŸ’ážšáž†áž¶áŸ†áž„áž áŸ’ážœáž¶ážŸáŸŠáž¸ážŸ amongst many.   NaN  ... NaN    NaN   \n",
       "3                                         ShodanðŸ”®|   NaN  ... NaN    NaN   \n",
       "4                                     Carl Hilberg   NaN  ... NaN    NaN   \n",
       "\n",
       "  user_rt_id user_rt retweet_id  \\\n",
       "0        NaN     NaN        NaN   \n",
       "1        NaN     NaN        NaN   \n",
       "2        NaN     NaN        NaN   \n",
       "3        NaN     NaN        NaN   \n",
       "4        NaN     NaN        NaN   \n",
       "\n",
       "                                            reply_to  retweet_date  translate  \\\n",
       "0  [{'screen_name': 'El_Was_Taken', 'name': 'Elli...           NaN        NaN   \n",
       "1  [{'screen_name': 'fedtanyl', 'name': 'Fed For ...           NaN        NaN   \n",
       "2  [{'screen_name': 'pl4ma', 'name': 'plama', 'id...           NaN        NaN   \n",
       "3  [{'screen_name': 'Rimlee18', 'name': 'Rimlee',...           NaN        NaN   \n",
       "4  [{'screen_name': 'InnaSovsun', 'name': 'Inna S...           NaN        NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "# file_path = 'https://www.kaggle.com/towhidultonmoy/russia-vs-ukraine-tweets-datasetdaily-updated?select=filename.csv'\n",
    "# file_path = 'https://www.kaggle.com/towhidultonmoy/russia-vs-ukraine-tweets-datasetdaily-updated/download'\n",
    "# raw_tweets_df = pd.read_csv(file_path, encoding='latin-1', error_bad_lines=False, engine ='python', sep=',')\n",
    "raw_tweets_df = pd.read_csv('../../data/russia_vs_ukraine_tweets.csv')\n",
    "raw_tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10001 entries, 0 to 10000\n",
      "Data columns (total 36 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               10001 non-null  int64  \n",
      " 1   conversation_id  10001 non-null  int64  \n",
      " 2   created_at       10001 non-null  object \n",
      " 3   date             10001 non-null  object \n",
      " 4   time             10001 non-null  object \n",
      " 5   timezone         10001 non-null  int64  \n",
      " 6   user_id          10001 non-null  int64  \n",
      " 7   username         10001 non-null  object \n",
      " 8   name             10000 non-null  object \n",
      " 9   place            2 non-null      object \n",
      " 10  tweet            10001 non-null  object \n",
      " 11  language         10001 non-null  object \n",
      " 12  mentions         10001 non-null  object \n",
      " 13  urls             10001 non-null  object \n",
      " 14  photos           10001 non-null  object \n",
      " 15  replies_count    10001 non-null  int64  \n",
      " 16  retweets_count   10001 non-null  int64  \n",
      " 17  likes_count      10001 non-null  int64  \n",
      " 18  hashtags         10001 non-null  object \n",
      " 19  cashtags         10001 non-null  object \n",
      " 20  link             10001 non-null  object \n",
      " 21  retweet          10001 non-null  bool   \n",
      " 22  quote_url        986 non-null    object \n",
      " 23  video            10001 non-null  int64  \n",
      " 24  thumbnail        1120 non-null   object \n",
      " 25  near             0 non-null      float64\n",
      " 26  geo              0 non-null      float64\n",
      " 27  source           0 non-null      float64\n",
      " 28  user_rt_id       0 non-null      float64\n",
      " 29  user_rt          0 non-null      float64\n",
      " 30  retweet_id       0 non-null      float64\n",
      " 31  reply_to         10001 non-null  object \n",
      " 32  retweet_date     0 non-null      float64\n",
      " 33  translate        0 non-null      float64\n",
      " 34  trans_src        0 non-null      float64\n",
      " 35  trans_dest       0 non-null      float64\n",
      "dtypes: bool(1), float64(10), int64(8), object(17)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get basic summary\n",
    "raw_tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 10001\n",
       "conversation_id     7211\n",
       "created_at          6510\n",
       "date                   1\n",
       "time                6510\n",
       "timezone               1\n",
       "user_id             7169\n",
       "username            7169\n",
       "name                7082\n",
       "place                  2\n",
       "tweet               9912\n",
       "language              39\n",
       "mentions             422\n",
       "urls                2122\n",
       "photos               944\n",
       "replies_count         32\n",
       "retweets_count        54\n",
       "likes_count          104\n",
       "hashtags            1171\n",
       "cashtags              15\n",
       "link               10001\n",
       "retweet                1\n",
       "quote_url            835\n",
       "video                  2\n",
       "thumbnail           1096\n",
       "near                   0\n",
       "geo                    0\n",
       "source                 0\n",
       "user_rt_id             0\n",
       "user_rt                0\n",
       "retweet_id             0\n",
       "reply_to            3467\n",
       "retweet_date           0\n",
       "translate              0\n",
       "trans_src              0\n",
       "trans_dest             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique values\n",
    "raw_tweets_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'conversation_id', 'created_at', 'date', 'time', 'timezone',\n",
       "       'user_id', 'username', 'name', 'place', 'tweet', 'language', 'mentions',\n",
       "       'urls', 'photos', 'replies_count', 'retweets_count', 'likes_count',\n",
       "       'hashtags', 'cashtags', 'link', 'retweet', 'quote_url', 'video',\n",
       "       'thumbnail', 'near', 'geo', 'source', 'user_rt_id', 'user_rt',\n",
       "       'retweet_id', 'reply_to', 'retweet_date', 'translate', 'trans_src',\n",
       "       'trans_dest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all columns\n",
    "raw_tweets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select relevant columns\n",
    "col_rename_map = {\n",
    "    'date': 'date',\n",
    "    'username': 'username',\n",
    "    # 'language': 'language'\n",
    "    'retweets_count': 'retweets',\n",
    "    'tweet': 'tweet',\n",
    "    'hashtags': 'hashtags'\n",
    "}\n",
    "\n",
    "tweets_df = raw_tweets_df[list(col_rename_map.keys())].rename(columns=col_rename_map)\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out non-english tweets\n",
    "# tweets_df = tweets_df[tweets_df[\"language\"]==\"en\"]\n",
    "# tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check duplicate tweets\n",
    "tweets_df['tweet'].duplicated(keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9912, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicate tweets\n",
    "tweets_df = tweets_df.drop_duplicates(subset='tweet', keep='first')\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Lemmatizer and stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cleaning functions\n",
    "\n",
    "def cleanText(tweet):\n",
    "\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('https?:\\/\\/[a-zA-Z0-9@:%._\\/+~#=?&;-]*', ' ', tweet)\n",
    "    tweet = re.sub('\\$[a-zA-Z0-9]*', ' ', tweet)\n",
    "    tweet = re.sub('\\@[a-zA-Z0-9]*', ' ', tweet)\n",
    "    tweet = re.sub('[^a-zA-Z\\']', ' ', tweet)\n",
    "    tweet = ' '.join( [w for w in tweet.split() if len(w)>1] )\n",
    "    \n",
    "    lem_stopwords = [lemma.lemmatize(x) for x in nltk.wordpunct_tokenize(tweet) \n",
    "                     if x not in stop_words]\n",
    "    tweet = ' '.join(lem_stopwords)\n",
    "    \n",
    "    return [lemma.lemmatize(x, nltk.corpus.reader.wordnet.VERB) for x in nltk.wordpunct_tokenize(tweet) \n",
    "             if x not in stop_words]\n",
    "\n",
    "\n",
    "def cleanHashtags(hashtags):\n",
    "\n",
    "    if hashtags:\n",
    "        hashtags = hashtags.lower()\n",
    "        hashtags = re.sub('\\$[a-zA-Z0-9]*', ' ', hashtags)\n",
    "        hashtags = re.sub('[^a-zA-Z]', ' ', hashtags)\n",
    "        hashtags=hashtags.strip() \n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "tweets_df['clean_tweet'] = tweets_df['tweet'].apply(lambda x: cleanText(x))\n",
    "tweets_df['cleaned_tweet'] = tweets_df['clean_tweet'].apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean hashtags\n",
    "tweets_df[\"hashtags\"] = tweets_df[\"hashtags\"].astype(str)\n",
    "tweets_df[\"hashtags\"] = tweets_df[\"hashtags\"].apply(lambda x: cleanHashtags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>voidbourn</td>\n",
       "      <td>0</td>\n",
       "      <td>@El_Was_Taken @mariya_GuO @jacksonhinklle This...</td>\n",
       "      <td></td>\n",
       "      <td>[take, guo, russia, usa, permanent, seat, unit...</td>\n",
       "      <td>take guo russia usa permanent seat unite natio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>applekappa1337</td>\n",
       "      <td>0</td>\n",
       "      <td>@fedtanyl Thomas Friedman sucks, but the artic...</td>\n",
       "      <td></td>\n",
       "      <td>[thomas, friedman, suck, article, simp, author...</td>\n",
       "      <td>thomas friedman suck article simp authoritaria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>mbw955</td>\n",
       "      <td>0</td>\n",
       "      <td>@pl4ma @TKensingtonian @freedomrideblog Not do...</td>\n",
       "      <td></td>\n",
       "      <td>[downplay, nazi, russian, aggression, greater,...</td>\n",
       "      <td>downplay nazi russian aggression greater russi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>shodanette</td>\n",
       "      <td>0</td>\n",
       "      <td>@Rimlee18 @_Chosokaba @gadhi_minosh @KittBarte...</td>\n",
       "      <td></td>\n",
       "      <td>[chosokaba, minosh, trade, agreement, equal, h...</td>\n",
       "      <td>chosokaba minosh trade agreement equal hence u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-23</td>\n",
       "      <td>chilberg11</td>\n",
       "      <td>0</td>\n",
       "      <td>@InnaSovsun Russia won't stop at Transnistria....</td>\n",
       "      <td></td>\n",
       "      <td>[russia, ', stop, transnistria, putin, claim, ...</td>\n",
       "      <td>russia ' stop transnistria putin claim moldova...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        username  retweets  \\\n",
       "0  2022-04-23       voidbourn         0   \n",
       "1  2022-04-23  applekappa1337         0   \n",
       "2  2022-04-23          mbw955         0   \n",
       "3  2022-04-23      shodanette         0   \n",
       "4  2022-04-23      chilberg11         0   \n",
       "\n",
       "                                               tweet hashtags  \\\n",
       "0  @El_Was_Taken @mariya_GuO @jacksonhinklle This...            \n",
       "1  @fedtanyl Thomas Friedman sucks, but the artic...            \n",
       "2  @pl4ma @TKensingtonian @freedomrideblog Not do...            \n",
       "3  @Rimlee18 @_Chosokaba @gadhi_minosh @KittBarte...            \n",
       "4  @InnaSovsun Russia won't stop at Transnistria....            \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  [take, guo, russia, usa, permanent, seat, unit...   \n",
       "1  [thomas, friedman, suck, article, simp, author...   \n",
       "2  [downplay, nazi, russian, aggression, greater,...   \n",
       "3  [chosokaba, minosh, trade, agreement, equal, h...   \n",
       "4  [russia, ', stop, transnistria, putin, claim, ...   \n",
       "\n",
       "                                       cleaned_tweet  \n",
       "0  take guo russia usa permanent seat unite natio...  \n",
       "1  thomas friedman suck article simp authoritaria...  \n",
       "2  downplay nazi russian aggression greater russi...  \n",
       "3  chosokaba minosh trade agreement equal hence u...  \n",
       "4  russia ' stop transnistria putin claim moldova...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime and extract month/year\n",
    "tweets_df['date'] = pd.to_datetime(tweets_df['date'])\n",
    "tweets_df['month'] = tweets_df['date'].dt.month\n",
    "tweets_df['year'] = tweets_df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['take guo russia usa permanent seat unite nation security council nothing repeat nothing say negate downplay fact sacrifice permanent none people come back nation primarily help',\n",
       " 'thomas friedman suck article simp authoritarianism basically say despite issue american democracy china russia fail provide alternative due incompetence whether ukraine shanghai covid',\n",
       " \"downplay nazi russian aggression greater russia denazification also tweet country like u settler country like australia canada ' issue genocide discus usual ignore\",\n",
       " 'chosokaba minosh trade agreement equal hence uk russia conflict agreement gas electric equate imperialism simple modern economics',\n",
       " \"russia ' stop transnistria putin claim moldova ukraine baltic nation always part greater russia want moldova moldova military strength alliance fend invasion easy grab\",\n",
       " 'geopolitical pilgrimage global leader india continue one return stronger relation trade india understand india mean india position russia well know change pm boris johnson',\n",
       " 'mold via est preocupada com amea da ssia de tomar sul da ucr nia',\n",
       " 'russia attack ukraine unopposed neighbour country go see trend belligerent state carry copy cat attack weaker state sadly pakistani aggression prime example thing come world danger eat',\n",
       " 'arab world view ukraine war russia economy',\n",
       " 'canadian ministry defense hand ukrainian force howitzer ammunition ukraine russia']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect sample of tweets\n",
    "filter_cond = (tweets_df['year']==2022) & (tweets_df['month']==4)\n",
    "list(tweets_df['cleaned_tweet'][filter_cond][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all tweets which do not have the words \"ukraine\" or \"russia\"\n",
    "# country_tweets_df = tweets_df.copy()\n",
    "\n",
    "# filter_words = ['ukraine', 'russia']\n",
    "# country_tweets_df = country_tweets_df[country_tweets_df[\"cleaned_tweet\"].str.contains('|'.join(filter_words))]\n",
    "# country_tweets_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thomas',\n",
       " 'friedman',\n",
       " 'suck',\n",
       " 'article',\n",
       " 'simp',\n",
       " 'authoritarianism',\n",
       " 'basically_say',\n",
       " 'despite',\n",
       " 'issue',\n",
       " 'american',\n",
       " 'democracy',\n",
       " 'china',\n",
       " 'russia',\n",
       " 'fail',\n",
       " 'provide',\n",
       " 'alternative',\n",
       " 'due',\n",
       " 'incompetence',\n",
       " 'whether',\n",
       " 'ukraine',\n",
       " 'shanghai',\n",
       " 'covid']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the \"clean_text\" column in the format supported by embeddings.\n",
    "sent = [row for row in tweets_df[\"clean_tweet\"]]\n",
    "\n",
    "# Automatically detect common phrases (bigrams) from a list of sentences.\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "\n",
    "w2v_model = Word2Vec(min_count=4,\n",
    "                     window=5,\n",
    "                     vector_size =300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     seed= 42,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "\n",
    "# Build vocab of the word2vec model from the custom data\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721155, 4092300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "w2v_model.train(sentences, \n",
    "                total_examples=w2v_model.corpus_count, \n",
    "                epochs=30, \n",
    "                report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('meet', 0.9997609257698059),\n",
       " ('advantage', 0.9997460246086121),\n",
       " ('cage', 0.9997429847717285),\n",
       " ('grow', 0.9997410774230957),\n",
       " ('consequence', 0.9997397661209106),\n",
       " ('wow', 0.9997391700744629),\n",
       " ('murder', 0.9997386932373047),\n",
       " ('stoprussianaggression', 0.9997381567955017),\n",
       " ('want', 0.9997380375862122),\n",
       " ('international', 0.999737560749054)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check similar words to war in the corpus\n",
    "w2v_model.wv.most_similar(positive=[\"war\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the word2vec model\n",
    "# w2v_model.save(\"models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the word2vec model\n",
    "# word_vectors = Word2Vec.load(\"word2vec.model\").wv\n",
    "word_vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate TfidfVectorizer \n",
    "vectorizer = TfidfVectorizer(min_df=3,\n",
    "                             sublinear_tf=True,\n",
    "#                              encoding=\"latin-1\",\n",
    "                             ngram_range=(1,2),\n",
    "                             stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "The TF-IDF vectorizer is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/experiments.ipynb Cell 34'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/experiments.ipynb#ch0000033?line=0'>1</a>\u001b[0m \u001b[39m# Fit vectorizer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/experiments.ipynb#ch0000033?line=1'>2</a>\u001b[0m \u001b[39m# X_train_tf = vectorizer.fit_transform(X_train.reset_index()[\"cleaned_text\"]).toarray()\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/experiments.ipynb#ch0000033?line=2'>3</a>\u001b[0m \u001b[39m# X_test_tf = vectorizer.transform(X_test.reset_index()[\"cleaned_text\"]).toarray()\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/experiments.ipynb#ch0000033?line=3'>4</a>\u001b[0m X_vectors \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mtransform(tweets_df[\u001b[39m\"\u001b[39;49m\u001b[39mcleaned_tweet\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mreset_index()[\u001b[39m'\u001b[39;49m\u001b[39mcleaned_tweet\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39mtoarray()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2090\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   2074\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, raw_documents):\n\u001b[1;32m   2075\u001b[0m     \u001b[39m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[1;32m   2076\u001b[0m \n\u001b[1;32m   2077\u001b[0m \u001b[39m    Uses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2088\u001b[0m \u001b[39m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[1;32m   2089\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2090\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m, msg\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mThe TF-IDF vectorizer is not fitted\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   2092\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mtransform(raw_documents)\n\u001b[1;32m   2093\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mtransform(X, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/validation.py:1341\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1336\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[1;32m   1337\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1338\u001b[0m     ]\n\u001b[1;32m   1340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[0;32m-> 1341\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"
     ]
    }
   ],
   "source": [
    "# Fit vectorizer\n",
    "# X_train_tf = vectorizer.fit_transform(X_train.reset_index()[\"cleaned_text\"]).toarray()\n",
    "# X_test_tf = vectorizer.transform(X_test.reset_index()[\"cleaned_text\"]).toarray()\n",
    "X_vectors = vectorizer.transform(tweets_df[\"cleaned_tweet\"].reset_index()['cleaned_tweet']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vectorizer\n",
    "# vectorizer = load('./models/vectorizer/russia_ukraine_vectorizer.joblib')\n",
    "vectorizer = load('../pipeline_1/models/vectorizer/slava_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>clean_tweet_words</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment_val</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4/23/22</td>\n",
       "      <td>voidbourn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@El_Was_Taken @mariya_GuO @jacksonhinklle This...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['take', 'guo', 'russia', 'usa', 'permanent', ...</td>\n",
       "      <td>take guo russia usa permanent seat unite natio...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4/23/22</td>\n",
       "      <td>applekappa1337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@fedtanyl Thomas Friedman sucks, but the artic...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['thomas', 'friedman', 'suck', 'article', 'sim...</td>\n",
       "      <td>thomas friedman suck article simp authoritaria...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4/23/22</td>\n",
       "      <td>mbw955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@pl4ma @TKensingtonian @freedomrideblog Not do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['downplay', 'nazi', 'russian', 'aggression', ...</td>\n",
       "      <td>downplay nazi russian aggression greater russi...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4/23/22</td>\n",
       "      <td>shodanette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@Rimlee18 @_Chosokaba @gadhi_minosh @KittBarte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['chosokaba', 'minosh', 'trade', 'agreement', ...</td>\n",
       "      <td>chosokaba minosh trade agreement equal hence u...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4/23/22</td>\n",
       "      <td>chilberg11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@InnaSovsun Russia won't stop at Transnistria....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['russia', 'stop', 'transnistria', 'putin', 'c...</td>\n",
       "      <td>russia stop transnistria putin claim moldova u...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0     date        username  retweets  \\\n",
       "0          0  4/23/22       voidbourn       0.0   \n",
       "1          1  4/23/22  applekappa1337       0.0   \n",
       "2          2  4/23/22          mbw955       0.0   \n",
       "3          3  4/23/22      shodanette       0.0   \n",
       "4          4  4/23/22      chilberg11       0.0   \n",
       "\n",
       "                                               tweet hashtags  \\\n",
       "0  @El_Was_Taken @mariya_GuO @jacksonhinklle This...      NaN   \n",
       "1  @fedtanyl Thomas Friedman sucks, but the artic...      NaN   \n",
       "2  @pl4ma @TKensingtonian @freedomrideblog Not do...      NaN   \n",
       "3  @Rimlee18 @_Chosokaba @gadhi_minosh @KittBarte...      NaN   \n",
       "4  @InnaSovsun Russia won't stop at Transnistria....      NaN   \n",
       "\n",
       "                                   clean_tweet_words  \\\n",
       "0  ['take', 'guo', 'russia', 'usa', 'permanent', ...   \n",
       "1  ['thomas', 'friedman', 'suck', 'article', 'sim...   \n",
       "2  ['downplay', 'nazi', 'russian', 'aggression', ...   \n",
       "3  ['chosokaba', 'minosh', 'trade', 'agreement', ...   \n",
       "4  ['russia', 'stop', 'transnistria', 'putin', 'c...   \n",
       "\n",
       "                                         clean_tweet   day  month  \\\n",
       "0  take guo russia usa permanent seat unite natio...  23.0    4.0   \n",
       "1  thomas friedman suck article simp authoritaria...  23.0    4.0   \n",
       "2  downplay nazi russian aggression greater russi...  23.0    4.0   \n",
       "3  chosokaba minosh trade agreement equal hence u...  23.0    4.0   \n",
       "4  russia stop transnistria putin claim moldova u...  23.0    4.0   \n",
       "\n",
       "   sentiment_val sentiment  \n",
       "0            1.0  positive  \n",
       "1            1.0  positive  \n",
       "2            1.0  positive  \n",
       "3            1.0  positive  \n",
       "4            1.0  positive  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv('./data/transformed/russia_ukraine_sentiment.csv')\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131090 entries, 0 to 131089\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         65554 non-null  object \n",
      " 1   date               37733 non-null  object \n",
      " 2   username           37733 non-null  object \n",
      " 3   retweets           37733 non-null  object \n",
      " 4   tweet              37733 non-null  object \n",
      " 5   hashtags           1717 non-null   object \n",
      " 6   clean_tweet_words  9912 non-null   object \n",
      " 7   clean_tweet        9888 non-null   object \n",
      " 8   day                9911 non-null   float64\n",
      " 9   month              9911 non-null   float64\n",
      " 10  sentiment_val      9911 non-null   float64\n",
      " 11  sentiment          9911 non-null   object \n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>retweets</th>\n",
       "      <th>tweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>clean_tweet_words</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>sentiment_val</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9870</th>\n",
       "      <td>9982</td>\n",
       "      <td>4/23/22</td>\n",
       "      <td>tompainetoday</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trending Now:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9871</th>\n",
       "      <td>#Ukraine | #Russia | #After | #Russian | #Mcca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Unnamed: 0     date  \\\n",
       "9870                                               9982  4/23/22   \n",
       "9871  #Ukraine | #Russia | #After | #Russian | #Mcca...      NaN   \n",
       "\n",
       "           username  retweets           tweet hashtags clean_tweet_words  \\\n",
       "9870  tompainetoday       0.0  Trending Now:       NaN               NaN   \n",
       "9871            NaN       NaN             NaN      NaN               NaN   \n",
       "\n",
       "     clean_tweet  day  month  sentiment_val sentiment  \n",
       "9870         NaN  NaN    NaN            NaN       NaN  \n",
       "9871         NaN  NaN    NaN            NaN       NaN  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[~x['clean_tweet'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9912 entries, 0 to 10000\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           9912 non-null   datetime64[ns]\n",
      " 1   username       9912 non-null   object        \n",
      " 2   retweets       9912 non-null   int64         \n",
      " 3   tweet          9912 non-null   object        \n",
      " 4   hashtags       9912 non-null   object        \n",
      " 5   clean_tweet    9912 non-null   object        \n",
      " 6   cleaned_tweet  9912 non-null   object        \n",
      " 7   month          9912 non-null   int64         \n",
      " 8   year           9912 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(3), object(5)\n",
      "memory usage: 774.4+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3648"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text using vectorizer\n",
    "X_vectors = vectorizer.transform(tweets_df[\"cleaned_tweet\"].reset_index()['cleaned_tweet']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9912, 3648)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load linearSVC\n",
    "linearSVC_model = load('../pipeline_1/models/linear_svc/slava_linearSVC.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3648"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearSVC_model.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load linearSVC\n",
    "multiNB_model = load('../pipeline_1/models/multi_nb/slava_multinomialNB.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3648"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiNB_model.n_features_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3648)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_idx, param_name = next(((i, x) for i, x in enumerate(['n_features_in_']) if hasattr(multiNB_model, x)), None)\n",
    "model_param = getattr(multiNB_model, param_name)\n",
    "if callable(model_param):\n",
    "    model_shape = model_param()\n",
    "else:\n",
    "    model_shape = model_param\n",
    "param_idx, model_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1.0, 'class_prior': None, 'fit_prior': True}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(multiNB_model, 'get_params')()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate prediction\n",
    "svc_predict = linearSVC_model.predict(X_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take guo russia usa permanent seat unite nation security council nothing repeat nothing say negate downplay fact sacrifice permanent none people come back nation primarily help -1\n",
      "thomas friedman suck article simp authoritarianism basically say despite issue american democracy china russia fail provide alternative due incompetence whether ukraine shanghai covid -1\n",
      "downplay nazi russian aggression greater russia denazification also tweet country like u settler country like australia canada ' issue genocide discus usual ignore -1\n",
      "chosokaba minosh trade agreement equal hence uk russia conflict agreement gas electric equate imperialism simple modern economics -1\n",
      "russia ' stop transnistria putin claim moldova ukraine baltic nation always part greater russia want moldova moldova military strength alliance fend invasion easy grab -1\n",
      "geopolitical pilgrimage global leader india continue one return stronger relation trade india understand india mean india position russia well know change pm boris johnson -1\n",
      "mold via est preocupada com amea da ssia de tomar sul da ucr nia -1\n",
      "russia attack ukraine unopposed neighbour country go see trend belligerent state carry copy cat attack weaker state sadly pakistani aggression prime example thing come world danger eat -1\n",
      "arab world view ukraine war russia economy -1\n",
      "canadian ministry defense hand ukrainian force howitzer ammunition ukraine russia -1\n"
     ]
    }
   ],
   "source": [
    "# connect predictions with outputs\n",
    "for i in range(10):\n",
    "\tprint(tweets_df[\"cleaned_tweet\"].iloc[i], svc_predict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map sentiment encodings\n",
    "\n",
    "emotion = { 0: \"neutral\", 1: \"positive\", -1: \"negative\" }\n",
    "\n",
    "k = np.array(list(emotion.keys()))\n",
    "v = np.array(list(emotion.values()))\n",
    "\n",
    "print(k)\n",
    "print(v)\n",
    "\n",
    "mapping_arr = np.zeros(k.max()+1, dtype=v.dtype) #k,v from approach #1\n",
    "print(mapping_arr)\n",
    "mapping_arr[k] = v\n",
    "\n",
    "sent_predictions = mapping_arr[svc_predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build df from predictions\n",
    "\n",
    "tweet_sentiments = pd.DataFrame(zip(tweets_df['cleaned_tweet'], sent_predictions), columns=['tweet', 'sentiments_val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pie chart of Sentiment Distribution of words\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(7,7)\n",
    "colors = [\"cyan\",\"pink\",\"yellow\"]\n",
    "\n",
    "pie_df = tweet_sentiments['sentiments_val'].value_counts().reset_index()\n",
    "\n",
    "plt.pie(pie_df['sentiments_val'],\n",
    "        labels=pie_df[\"index\"],\n",
    "        radius=2,\n",
    "        colors=colors,\n",
    "        autopct=\"%1.1f%%\")\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.title('Sentiment Distribution of Tweets', fontsize=20)\n",
    "plt.show()\n",
    "pie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect keyword sentiment\n",
    "keywords=['russia']\n",
    "pattern = '|'.join(keywords)\n",
    "keyword_sent_df = tweet_sentiments[(tweet_sentiments[\"tweet\"].str.contains(pattern))]\n",
    "sns.countplot(x=keyword_sent_df[\"sentiments_val\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10d883baf2d2c020187d16fb74e1bc85e676b385dd78044a08a209b4abcafece"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
