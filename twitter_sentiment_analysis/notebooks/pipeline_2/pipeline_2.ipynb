{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis Pipeline #2\n",
    "*Refer to `notebooks/README.md` for an explanation of the various pipelines*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import re\n",
    "import json\n",
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# Importing datasets\n",
    "import opendatasets as od\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load as jl_load\n",
    "from joblib import dump as jl_dump\n",
    "\n",
    "# Graphing/Visualizing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined\n",
    "from pipeline_1 import pipeline1, formatParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IMPORT_PARAMS = {\n",
    "    'data_path': 'https://www.kaggle.com/datasets/towhidultonmoy/russia-vs-ukraine-tweets-datasetdaily-updated{version}',\n",
    "    # 'version': 1,\n",
    "    'local_path': '../../data/russia_vs_ukraine_tweets{version}.csv',\n",
    "    'new_data': False\n",
    "}\n",
    "\n",
    "\n",
    "PIPE1_PARAMS = {\n",
    "    'control': {\n",
    "        'build_models': True\n",
    "        # 'config': '../pipeline_1/config/config.json',\n",
    "        # 'nb_export': '../pipeline_3/pipeline_2'\n",
    "    },\n",
    "    'extract': {\n",
    "        'clean_tweet': [], # list of regex rules\n",
    "        'clean_hashtag': [], # list of regex rules\n",
    "        'column_mappings': {\n",
    "            'date': 'date',\n",
    "            'user_name': 'username',\n",
    "            'retweets': 'retweets',\n",
    "            'text': 'tweet',\n",
    "            'hashtags': 'hashtags'\n",
    "        },\n",
    "        # 'filter_words': ['ukraine', 'russia', 'zelensky'], # Only process tweets containing these words\n",
    "        'save_transform': './data/transformed/russia_ukraine_sentiment_{timestamp}.csv'\n",
    "    },\n",
    "    'transform': {\n",
    "        'load_word_vec': '',\n",
    "        'save_word_vec': './models/russia_ukraine_word_vec_{timestamp}.model',\n",
    "        'word_vec_args': {},\n",
    "        'load_kmeans': '',\n",
    "        'save_kmeans': './models/russia_ukraine_kmeans_{timestamp}.joblib',\n",
    "        'kmeans_args': {},\n",
    "        'display_terms': 25,\n",
    "        'load_embeddings': '',\n",
    "        'save_embeddings': './data/embeddings/russia_ukraine_words_{timestamp}.csv',\n",
    "        'sentiment_threshold': 0.15,\n",
    "        'sentiment_map': { \n",
    "            -1: \"negative\",\n",
    "            0: \"neutral\", \n",
    "            1: \"positive\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "PIPE1_TRANSFORM_ARGS = {\n",
    "}\n",
    "\n",
    "PIPE1_MODEL_ARGS = {\n",
    "    'load_vectorizer': '',\n",
    "    'save_vectorizer': './models/russia_ukraine_vectorizer_{timestamp}.joblib',\n",
    "    'vectorizer_args': {},\n",
    "    'load_svc': '',\n",
    "    'save_svc': './models/russia_ukraine_linearSVC_{timestamp}.joblib',\n",
    "    'load_nb': '',\n",
    "    'save_nb': './models/russia_ukraine_multinomialNB_{timestamp}.joblib'\n",
    "}\n",
    "\n",
    "\n",
    "PIPE2_CONTROL_PARAMS = {\n",
    "    'config': './config/config_{timestamp}.json'\n",
    "}\n",
    "\n",
    "PIPE2_EXTRACT_ARGS = {\n",
    "    'load_transform': './data/transformed/russia_ukraine_sentiment.csv',\n",
    "    'load_svc': '../pipeline_1/models/slava_linearSVC.joblib',\n",
    "    'load_nb': '../pipeline_1/models/slava_multinomialNB.joblib',\n",
    "    'load_vectorizer': '../pipeline_1/models/slava_vectorizer.joblib',\n",
    "    'x_col': 'clean_tweet',\n",
    "    'y_col': 'sentiment_val'\n",
    "}\n",
    "\n",
    "PIPE2_MODEL_ARGS = {\n",
    "}\n",
    "\n",
    "PIPE2_INSPECT_ARGS = {\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `extract` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract(tweets_df, x_col, y_col, **kwargs):\n",
    "\n",
    "    # Load vectorizer\n",
    "    if (vector_loc := kwargs.get('load_vectorizer')):\n",
    "        vectorizer = jl_load(vector_loc)\n",
    "    else: # need associated vectorizer \n",
    "        return\n",
    "    \n",
    "    X = tweets_df[x_col]\n",
    "    y = tweets_df[y_col]\n",
    "\n",
    "    # Transform text using vectorizer\n",
    "    X_test = vectorizer.transform(X.reset_index()[x_col]).toarray()\n",
    "    X_test_fit = vectorizer.fit_transform(X.reset_index()[x_col]).toarray()\n",
    "\n",
    "    # Collect features\n",
    "    feature_names = vectorizer.get_feature_names_out() \n",
    "\n",
    "    ## Isn't this just a groupby?\n",
    "    # Convert each sentiment to df (performance should be OK, small dataset)\n",
    "    pos_df = tweets_df[tweets_df[\"sentiment\"]==\"positive\"]\n",
    "    neg_df = tweets_df[tweets_df[\"sentiment\"]==\"negative\"]\n",
    "    neu_df = tweets_df[tweets_df[\"sentiment\"]==\"neutral\"]\n",
    "\n",
    "    # Combine all sentiments in one df\n",
    "    sentiments_df_list = [pos_df, neg_df, neu_df] \n",
    "    agg_sentiment_df = pd.concat(sentiments_df_list)\n",
    "\n",
    "    # Load linearSVC\n",
    "    collected_models = {}\n",
    "    if (svc_loc := kwargs.get('load_svc')):\n",
    "        collected_models['linear_svc'] = {\n",
    "            'model': jl_load(svc_loc),\n",
    "            'x_test': X_test,\n",
    "            'x_test_fit': X_test_fit,\n",
    "            'features': feature_names\n",
    "        }\n",
    "    \n",
    "    # Load MultinomialNB\n",
    "    if (nb_loc := kwargs.get('load_nb')):\n",
    "        collected_models['multi_nb'] = {\n",
    "            'model': jl_load(nb_loc),\n",
    "            'y_test': y,\n",
    "            'x_test': X_test,\n",
    "            'x_test_fit': X_test_fit,\n",
    "            'features': feature_names\n",
    "        }\n",
    "    \n",
    "    return collected_models, agg_sentiment_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `transform` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(models, tweets_df, config_path, **kwargs):\n",
    "\n",
    "    # Import pipeline 1's config\n",
    "    p1_config_data = {}\n",
    "    with open(config_path, 'r') as f:\n",
    "        p1_config_data = json.load(f)\n",
    "    \n",
    "    # Map sentiment encodings\n",
    "    p1_emotion = p1_config_data['sentiment_vals']['value_mapping']\n",
    "\n",
    "    emot_codes = np.array([int(x) for x in p1_emotion.keys()])\n",
    "    emot_labels = np.array(list(p1_emotion.values()))\n",
    "\n",
    "    map_offset = np.abs(emot_codes.min())\n",
    "    mapping_arr = np.zeros(len(emot_codes), dtype=emot_labels.dtype)\n",
    "    mapping_arr[emot_codes+map_offset] = emot_labels\n",
    "\n",
    "    model_predictions = {}\n",
    "    for model_name, model_info in models.items():\n",
    "        model = model_info['model']\n",
    "        X_test = model_info['x_test']\n",
    "\n",
    "        # Generate prediction\n",
    "        predicts = model.predict(X_test)\n",
    "\n",
    "        predictions_arr = mapping_arr[predicts]\n",
    "\n",
    "        # Build df from predictions\n",
    "        predictions_df = pd.DataFrame(zip(tweets_df['clean_tweet'], tweets_df['sentiment_val'], predictions_arr), \n",
    "                                        columns=['clean_tweet', 'sentiment_val', 'sentiment'])\n",
    "        \n",
    "        model_predictions[model_name] = predictions_df\n",
    "\n",
    "    return model_predictions, mapping_arr                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `inspect` function\n",
    "Used to calculate each model's performance\n",
    "\n",
    "#### **Cluster** model validation\n",
    "1. Internal validation\n",
    "    - Typically will combine cohesion (within each cluster) and separation (between different clusters)\n",
    "    - Compute the validation score of each cluster and then uses weights in the aggregation to produce a final score for the entire model\n",
    "\n",
    "2. External validation\n",
    "    - Necessary to have *true* cluster labels\n",
    "    - Measure the statistical similarity between the *true* cluster labels and the actual values\n",
    "\n",
    "#### **Classification** metrics\n",
    "1. Classification Accuracy:\n",
    "    - The ratio of correct predictions to the total number of predicitions\n",
    "    - Popular but flawed (often misused/misinterpreted); there are two criteria to meet for this calculation:\n",
    "        1. Equal number of observations in all classes\n",
    "        2. All predictions and prediction errors are equally important\n",
    "2. Log Loss\n",
    "    - Evaluates the predictions of probabilities of membership to a given class\n",
    "    - Can be seen as a measure of confidence for a prediction algorithm\n",
    "3. Area Under ROC Curve\n",
    "    - Designed for binary classification problems\n",
    "4. Confusion Matrix\n",
    "    - Provides the accuracy of a model which has two or more classes\n",
    "    - Presents the predicitions in relation to the accuracy outcome\n",
    "5. Classificaiton Report\n",
    "    - `scikit-learn`'s function to summarize a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small evaluation functions to be used by `inspect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MetricReports:\n",
    "\n",
    "    def getTests():\n",
    "        return {\n",
    "            'cross_val': MetricReports.crossValidation,\n",
    "            'confusion': MetricReports.confusionMatrix,\n",
    "            'classification': MetricReports.classificationReport\n",
    "        }\n",
    "\n",
    "    def execute(model, features, y_test, y_pred, **kwargs):\n",
    "        return [\n",
    "            MetricReports.crossValidation(model, features, y_pred, kwargs),\n",
    "            MetricReports.confusionMatrix(y_test, y_pred),\n",
    "            MetricReports.classificationReport(y_test, y_pred)\n",
    "        ]\n",
    "\n",
    "    ## Metric Functions ##\n",
    "\n",
    "    def crossValidation(model, features, y_pred, scoring=['accuracy'], kfold=5):\n",
    "        res = []\n",
    "        for score in scoring:\n",
    "            res.append({\n",
    "                'name': f'CV Classification - {score}',\n",
    "                'result': cross_val_score(estimator=model,\n",
    "                                            X=features, \n",
    "                                            y=y_pred, \n",
    "                                            scoring=score, \n",
    "                                            cv=kfold)\n",
    "            })\n",
    "        return res\n",
    "\n",
    "    def confusionMatrix(y_test, y_pred):\n",
    "        ''' FIXME: This might not be a valid metric... not sure if it can handle unlabeled data\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Confusion Matrix',\n",
    "            'result': metrics.confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        }\n",
    "\n",
    "    def classificationReport(y_test, y_pred):\n",
    "        ''' FIXME: This might not be a valid metric... not sure if it can handle unlabeled data\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Classification Report',\n",
    "            'result': metrics.classification_report(y_true=y_test, y_pred=y_pred, output_dict=True)\n",
    "        }\n",
    "\n",
    "\n",
    "## Best suited for unsupervised clustering algorithms ##\n",
    "\n",
    "class MetricScores:\n",
    "\n",
    "    def getTests():\n",
    "        return {\n",
    "            'silhouette': MetricScores.silhouetteScore,\n",
    "            'calinski_harabaz': MetricScores.calinskiHarabaz,\n",
    "            'dabies_bouldin': MetricScores.dabiesBouldin,\n",
    "            'mean_acc': MetricScores.meanAccuracy\n",
    "        }\n",
    "\n",
    "    def execute(model, features, y_pred):\n",
    "        return [\n",
    "            MetricScores.silhouetteScore(features, y_pred),\n",
    "            MetricScores.calinskiHarabaz(features, y_pred),\n",
    "            MetricScores.dabiesBouldin(features, y_pred),\n",
    "            MetricScores.meanAccuracy(model, features, y_pred)\n",
    "        ]\n",
    "\n",
    "    ## Metric Functions ##\n",
    "\n",
    "    def silhouetteScore(features, y_pred):\n",
    "        ''' Attempts to describe how similar a datapoint is to other datapoints in its cluster, \n",
    "        relative to datapoints not in its cluster (aggregated over all datapoints to get the score for \n",
    "        an overall clustering). It evaluates how ‘distinct’ the clusters are in space\n",
    "        It's bounded between -1 and 1. Closer to -1 suggests incorrect clustering, while \n",
    "        closer to +1 shows that each cluster is very dense.\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Silhouette Score',\n",
    "            'result': metrics.silhouette_score(X=features, labels=y_pred)\n",
    "        }\n",
    "\n",
    "    def calinskiHarabaz(features, y_pred):\n",
    "        ''' A ratio of the variance of a datapoint compared to points in other clusters, \n",
    "        against the variance compared to points within its cluster. This score is not bounded.\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Calinski Harabaz Index',\n",
    "            'result': metrics.calinski_harabasz_score(X=features, labels=y_pred)\n",
    "        }\n",
    "\n",
    "    def dabiesBouldin(features, y_pred):\n",
    "        ''' The average similarity measure of each cluster with its most similar cluster, \n",
    "        where similarity is the ratio of within-cluster distances to between-cluster distances. \n",
    "        Thus, clusters which are farther apart and less dispersed will result in a better score.\n",
    "        The minimum score is zero, with lower values indicating better clustering.\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Davies-Bouldin Index',\n",
    "            'result': metrics.davies_bouldin_score(X=features, labels=y_pred)\n",
    "        }\n",
    "\n",
    "    def meanAccuracy(model, features, y_pred):\n",
    "        '''\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Mean Accuracy',\n",
    "            'result': model.score(X=features, y=y_pred)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inspect(models, prediction_dfs, tweets_df, **kwargs):\n",
    "\n",
    "    # Set up variables\n",
    "    cv_scores = kwargs.get('cv_scores', ['accuracy'])\n",
    "    crossVal_accuracies = { x: [] for x in cv_scores }\n",
    "\n",
    "    test_names = list(MetricReports.getTests().keys()) + list(MetricScores.getTests().keys())\n",
    "    metric_results = { m: { k: [] for k in test_names } for m in models.keys() }\n",
    "    cv_dfs = {m: {} for m in models.keys()}\n",
    "\n",
    "    ## Begin evaluations\n",
    "\n",
    "    for model_name, model_info in models.items():\n",
    "\n",
    "        # y_test = tweets_df['sentiment_val']\n",
    "        y_test = model_info['y_test']\n",
    "        y_pred = prediction_dfs[model_name]['sentiment_val']\n",
    "\n",
    "        X_test = model_info['x_test']\n",
    "        X_test_fit = model_info['x_test_fit']\n",
    "\n",
    "        metric_reports = MetricReports.execute(model=model_info['model'], \n",
    "                                                features=X_test, \n",
    "                                                y_test=y_test, \n",
    "                                                y_pred=y_pred, \n",
    "                                                scoring=cv_scores, \n",
    "                                                kfold=kwargs.get('kfold'))\n",
    "        metric_scores = MetricScores.execute(model=model_info['model'], \n",
    "                                                features=X_test, \n",
    "                                                y_pred=y_pred)\n",
    "\n",
    "        metric_results[model_name] = metric_reports + metric_scores\n",
    "\n",
    "        # Aggregate cross validation results\n",
    "        for res in metric_reports:\n",
    "            if 'CV' in res['name']:\n",
    "                score_name = res['name'].split(' ')[-1]\n",
    "                indexed_acc = [(model_name, idx, acc) for idx, acc in enumerate(res['result'])]\n",
    "                crossVal_accuracies[score_name].append(\n",
    "                    pd.DataFrame(indexed_acc, columns=['model_name', 'fold_idx', score_name]))\n",
    "        \n",
    "        # Combine cross val results by scoring type\n",
    "        for score_type, models in crossVal_accuracies.items():\n",
    "            cv_dfs[model_name][score_type] = pd.concat(models)\n",
    "\n",
    "    # Create a dict of Sentiment_val\n",
    "    sentiment_id_df = tweets_df[['sentiment_val', 'sentiment']].drop_duplicates().sort_values('sentiment_val')\n",
    "    sentiment_to_id = dict(sentiment_id_df.values)\n",
    "\n",
    "    metric_results['sentiment_maps'] = {\n",
    "        'sentiment_id': sentiment_id_df,\n",
    "        'sentiment_to': sentiment_to_id\n",
    "    }\n",
    "\n",
    "\n",
    "    return metric_results, cv_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `load` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(predictions, results, cv_dfs=[], io_options={}):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build `pipeline` function using above processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline2(pipe1_args, extract_args={}, model_args={}, inspect_args={}, control_params={}):\n",
    "\n",
    "    \n",
    "    if not extract_args.get('sentiment_map'):\n",
    "        extract_args['sentiment_map'] = { -1: \"negative\", 0: \"neutral\", 1: \"positive\" }\n",
    "\n",
    "    print('--- Beginning Part 1: transform new dataset using Pipeline 1 ---\\n')\n",
    "\n",
    "\n",
    "    if (existing_transform := pipe1_args.get('load_transform')):\n",
    "        p1_sentiment_df = pd.read_csv(existing_transform)\n",
    "\n",
    "    else:\n",
    "        # Can reuse pipeline 1 without building models\n",
    "        p1_sentiment_df, _, _ = pipeline1(**pipe1_args)\n",
    "\n",
    "    if not p1_sentiment_df.empty:\n",
    "\n",
    "        print('Completed Pipelin 1.\\n\\n--- Beginning Part 2: assess accuracy of Pipeline 1 models ---')\n",
    "        print('Stage 1: Extracting...')\n",
    "        config = defaultdict(dict)\n",
    "\n",
    "        models_dict, sentiment_df = extract(tweets_df=p1_sentiment_df,\n",
    "                                                    **extract_args)\n",
    "\n",
    "        print('Completed Stage 1.\\n\\nStage 2: Transforming...')\n",
    "\n",
    "        model_predictions, mapping_arr = model(models=models_dict,\n",
    "                                                tweets_df=p1_sentiment_df,\n",
    "                                                config=pipe1_args.get('config'),\n",
    "                                                **model_args)\n",
    "        \n",
    "        print('Completed Stage 2.\\n\\nStage 2.5: Analyzing...')\n",
    "\n",
    "        metric_results, crossVal_dfs = inspect(models=models_dict, \n",
    "                                                        prediction_dfs=model_predictions,\n",
    "                                                        tweets_df=p1_sentiment_df,\n",
    "                                                        **inspect_args)\n",
    "\n",
    "        print('Completed Stage 2.5.\\n\\nStage 3: Loading...')\n",
    "        load(predictions=model_predictions, results=metric_results, cv_dfs=crossVal_dfs, **control_params)\n",
    "        \n",
    "        # Need to append to Pipeline 1 config...\n",
    "        with open(control_params.get('config', './config.json'), 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "    print('\\n<done>')\n",
    "    return p1_sentiment_df, model_predictions, metric_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Beginning Part 1: transform new dataset using Pipeline 1 ---\n",
      "\n",
      "Stage 1: Extracting...\n",
      "Downloading russia-vs-ukraine-tweets-datasetdaily-updated.zip to ../../data/russia-vs-ukraine-tweets-datasetdaily-updated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.08M/2.08M [00:00<00:00, 10.3MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['user_name', 'retweets', 'text'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000028?line=19'>20</a>\u001b[0m p2_inspect_args, _ \u001b[39m=\u001b[39m formatParams(PIPE2_INSPECT_ARGS, curr_time)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000028?line=20'>21</a>\u001b[0m p2_control_params, _ \u001b[39m=\u001b[39m formatParams(PIPE2_CONTROL_PARAMS, curr_time)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000028?line=23'>24</a>\u001b[0m ru_sentiment_df, ru_predictions, model_metrics \u001b[39m=\u001b[39m pipeline2(pipe1_args\u001b[39m=\u001b[39;49mpipe1_args,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000028?line=24'>25</a>\u001b[0m                                                             extract_args\u001b[39m=\u001b[39;49mp2_extract_args,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000028?line=25'>26</a>\u001b[0m                                                             model_args\u001b[39m=\u001b[39;49mp2_model_args,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000028?line=26'>27</a>\u001b[0m                                                             inspect_args\u001b[39m=\u001b[39;49mp2_inspect_args,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000028?line=27'>28</a>\u001b[0m                                                             control_params\u001b[39m=\u001b[39;49mp2_control_params)\n",
      "\u001b[1;32m/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb Cell 20'\u001b[0m in \u001b[0;36mpipeline2\u001b[0;34m(pipe1_args, extract_args, model_args, inspect_args, control_params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000026?line=10'>11</a>\u001b[0m     p1_sentiment_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(existing_transform)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000026?line=12'>13</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000026?line=13'>14</a>\u001b[0m     \u001b[39m# Can reuse pipeline 1 without building models\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000026?line=14'>15</a>\u001b[0m     p1_sentiment_df, _, _ \u001b[39m=\u001b[39m pipeline1(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpipe1_args)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000026?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m p1_sentiment_df\u001b[39m.\u001b[39mempty:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_2.ipynb#ch0000026?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCompleted Pipelin 1.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m--- Beginning Part 2: assess accuracy of Pipeline 1 models ---\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py:677\u001b[0m, in \u001b[0;36mpipeline1\u001b[0;34m(import_path, import_params, extract_args, transform_args, model_args, control_params)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=672'>673</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mStage 1: Extracting...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=674'>675</a>\u001b[0m config \u001b[39m=\u001b[39m defaultdict(\u001b[39mdict\u001b[39m)\n\u001b[0;32m--> <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=676'>677</a>\u001b[0m all_tweets_df, target_df \u001b[39m=\u001b[39m extract(import_path\u001b[39m=\u001b[39;49mimport_path,\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=677'>678</a>\u001b[0m                             local_path\u001b[39m=\u001b[39;49mimport_params\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39mlocal_path\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m{\u001b[39;49;00mimport_path\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39m.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=678'>679</a>\u001b[0m                             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextract_args)\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=680'>681</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mCompleted Stage 1.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mStage 2: Transforming...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=681'>682</a>\u001b[0m transform_tweets_df, word_vecs, sentiment_defs \u001b[39m=\u001b[39m transform(filtered_df\u001b[39m=\u001b[39mtarget_df, \n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=682'>683</a>\u001b[0m                     cumulative_df\u001b[39m=\u001b[39mall_tweets_df,\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=683'>684</a>\u001b[0m                     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtransform_args)\n",
      "File \u001b[0;32m~/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py:205\u001b[0m, in \u001b[0;36mextract\u001b[0;34m(import_path, local_path, column_mappings, filter_words, **kargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=201'>202</a>\u001b[0m raw_tweets_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(local_path)\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=203'>204</a>\u001b[0m \u001b[39m# Rename columns\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=204'>205</a>\u001b[0m tweets_df \u001b[39m=\u001b[39m raw_tweets_df[\u001b[39mlist\u001b[39;49m(column_mappings\u001b[39m.\u001b[39;49mkeys())]\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39mcolumn_mappings) \\\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=205'>206</a>\u001b[0m                 \u001b[39mif\u001b[39;00m column_mappings \u001b[39melse\u001b[39;00m raw_tweets_df\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=207'>208</a>\u001b[0m \u001b[39m# Drop duplicate tweets\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/petergish/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/pipeline_1.py?line=208'>209</a>\u001b[0m tweets_df \u001b[39m=\u001b[39m tweets_df\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtweet\u001b[39m\u001b[39m'\u001b[39m, keep\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py?line=3508'>3509</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py?line=3509'>3510</a>\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py?line=3510'>3511</a>\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py?line=3512'>3513</a>\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py?line=3513'>3514</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5778'>5779</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5779'>5780</a>\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5781'>5782</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5783'>5784</a>\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5784'>5785</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5785'>5786</a>\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5841'>5842</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5843'>5844</a>\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> <a href='file:///Users/petergish/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/indexes/base.py?line=5844'>5845</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['user_name', 'retweets', 'text'] not in index\""
     ]
    }
   ],
   "source": [
    "# Format parameters\n",
    "data_import_params, curr_time = formatParams(DATA_IMPORT_PARAMS)\n",
    "\n",
    "p1_extract_args, _ = formatParams(PIPE1_EXTRACT_ARGS, curr_time)\n",
    "p1_transform_args, _ = formatParams(PIPE1_TRANSFORM_ARGS, curr_time)\n",
    "p1_model_args, _ = formatParams(PIPE1_MODEL_ARGS, curr_time)\n",
    "p1_control_params, _ = formatParams(PIPE1_CONTROL_PARAMS, curr_time)\n",
    "\n",
    "pipe1_args = {\n",
    "    'import_path': data_import_params['data_path'],\n",
    "    'import_params': data_import_params,\n",
    "    'extract_args': p1_extract_args,\n",
    "    'transform_args': p1_transform_args,\n",
    "    'model_args': p1_model_args,\n",
    "    'control_params': p1_control_params \n",
    "}\n",
    "\n",
    "p2_extract_args, _ = formatParams(PIPE2_EXTRACT_ARGS, curr_time)\n",
    "p2_model_args, _ = formatParams(PIPE2_MODEL_ARGS, curr_time)\n",
    "p2_inspect_args, _ = formatParams(PIPE2_INSPECT_ARGS, curr_time)\n",
    "p2_control_params, _ = formatParams(PIPE2_CONTROL_PARAMS, curr_time)\n",
    "\n",
    "\n",
    "ru_sentiment_df, ru_predictions, model_metrics = pipeline2(pipe1_args=pipe1_args,\n",
    "                                                            extract_args=p2_extract_args,\n",
    "                                                            model_args=p2_model_args,\n",
    "                                                            inspect_args=p2_inspect_args,\n",
    "                                                            control_params=p2_control_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10d883baf2d2c020187d16fb74e1bc85e676b385dd78044a08a209b4abcafece"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
