{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis Pipeline #2\n",
    "*Refer to `notebooks/README.md` for an explanation of the various pipelines*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built-in\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from functools import reduce \n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import load, dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/petergish/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/petergish/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/petergish/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../pipeline_1\")\n",
    "from modules.pipeline_1 import pipeline1\n",
    "sys.path.remove(\"../pipeline_1\")\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from import_data import importData\n",
    "from config_parser import buildConfig, mergeDicts\n",
    "from control_signal import ControlSignal, CONTROL_ACTIONS, CONTROL_FLAGS, processSignals\n",
    "from grapher import Grapher\n",
    "sys.path.remove(\"../utils\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `extract` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DEF_TYPES = [str, LinearSVC, MultinomialNB]\n",
    "MODEL_NUM_FEATURES = [\n",
    "        ('n_features_in_', lambda x: x.n_features_in_)\n",
    "    ]\n",
    "\n",
    "def extract(sentiment_dataset=None, slava_vectorizer=None, slava_models=None, \n",
    "                x_col='', y_col='', slava_config=None, **kwargs):\n",
    "    signals = []\n",
    "    existing_models = {}\n",
    "\n",
    "    if not sentiment_dataset:\n",
    "        signals.append(ControlSignal(CONTROL_ACTIONS.WARNING, CONTROL_FLAGS.INVALID_REQUIRED,\n",
    "                            'Missing sentiment dataset definition.'))\n",
    "    if not slava_vectorizer:\n",
    "        signals.append(ControlSignal(CONTROL_ACTIONS.WARNING, CONTROL_FLAGS.INVALID_REQUIRED,\n",
    "                            'Missing the slava vectorizer definition produced by Pipeline 1.'))\n",
    "    if not slava_models:\n",
    "        signals.append(ControlSignal(CONTROL_ACTIONS.WARNING, CONTROL_FLAGS.INVALID_REQUIRED,\n",
    "                            'Missing the slava prediction models definition(s) produced by Pipeline 1.'))\n",
    "    if signals:\n",
    "        return signals, None\n",
    "    if not x_col:\n",
    "        signals.append(ControlSignal(CONTROL_ACTIONS.ABORT, CONTROL_FLAGS.INVALID_REQUIRED,\n",
    "                        'Missing feature column definition for the sentiment dataset.'))\n",
    "    if not x_col:\n",
    "        signals.append(ControlSignal(CONTROL_ACTIONS.ABORT, CONTROL_FLAGS.INVALID_REQUIRED,\n",
    "                        'Missing label column definition for the sentiment dataset.'))\n",
    "    if signals:\n",
    "        return signals, None \n",
    "    \n",
    "\n",
    "    INVALID, VALID = 0, 1\n",
    "    searchParams = lambda keys, param: reduce(lambda d, k: d.get(k) , keys, param)\n",
    "    def validateObject(obj, allowed_types, expected_type=None, obj_protocol=None, required=False, err_signal=None, **kwargs): \n",
    "        if not hasattr(allowed_types, '__iter__') or isinstance(allowed_types, str) or allowed_types == str:\n",
    "            obj_type = allowed_types if isinstance(obj, allowed_types) else None\n",
    "        else:\n",
    "            obj_type = next((t for t in allowed_types if isinstance(obj, t)), None)\n",
    "        \n",
    "        if not obj_type:\n",
    "            if err_signal:\n",
    "                signals.append(err_signal)\n",
    "            return INVALID, None\n",
    "        \n",
    "        obj_signals, extracted_obj = importData(import_loc=obj, import_protocol=obj_protocol,\n",
    "                                        signals=signals, expected_type=expected_type, required=required, kwargs=kwargs)\n",
    "        signals.extend(obj_signals)\n",
    "        \n",
    "        if extracted_obj is None or (hasattr(extracted_obj,'size') and extracted_obj.size < 1):\n",
    "            return INVALID, None\n",
    "        \n",
    "        return VALID, extracted_obj\n",
    "        \n",
    "    \n",
    "    # Load sentiment df\n",
    "    valid_obj, sentiment_df = validateObject(obj=sentiment_dataset, obj_protocol=searchParams(['sentiment_dataset_protocol'], kwargs), \n",
    "                                    allowed_types=str, expected_type=pd.DataFrame, \n",
    "                                    err_signal=ControlSignal(CONTROL_ACTIONS.WARNING, CONTROL_FLAGS.MISSING_REQUIRED,\n",
    "                                        \"Missing ground-truth sentiment dataframe which is required.\"),\n",
    "                                    kwargs=kwargs)\n",
    "    if valid_obj == INVALID:\n",
    "        return signals, None\n",
    "\n",
    "    # Load vectorizer\n",
    "    valid_obj, vectorizer = validateObject(obj=slava_vectorizer, obj_protocol=searchParams(['slava_vectorizer_protocol'], kwargs),\n",
    "                                    allowed_types=str, expected_types=TfidfVectorizer, \n",
    "                                    err_signal=ControlSignal(CONTROL_ACTIONS.WARNING, CONTROL_FLAGS.MISSING_NECCESSARY, \n",
    "                                        'Must provide an existing vectorizer model associated with the sentiment data.'),\n",
    "                                    kwargs=kwargs)\n",
    "    if valid_obj == INVALID:\n",
    "        return signals, None\n",
    "        \n",
    "    num_vectorizer_features = len(vectorizer.idf_)    \n",
    "\n",
    "\n",
    "    # Load Pipeline 1 config\n",
    "    slava_config_data = {}\n",
    "    if isinstance(slava_config, str):\n",
    "        try:\n",
    "            with(open(slava_config, 'r') as f):\n",
    "                slava_config_data = json.load(f)\n",
    "        except:\n",
    "            signals.append(ControlSignal(CONTROL_ACTIONS.ABORT, CONTROL_FLAGS.IMPORT_EXCEPTION,\n",
    "                            f'Could not read Pipeline 1 configuration from {slava_config}'))\n",
    "            return signals, None\n",
    "    elif not isinstance(slava_config, dict):\n",
    "        signals.append(ControlSignal(CONTROL_ACTIONS.ABORT, CONTROL_FLAGS.MISSING_NECCESSARY,\n",
    "                            (f'Invalid argument type for `slava_config`: {type(slava_config)} - {slava_config}\\n' + \n",
    "                            'Expected str or dict')))\n",
    "        return signals, None\n",
    "    else:\n",
    "        slava_config_data = slava_config\n",
    "    \n",
    "    if not (model_config := slava_config_data.get('MODEL')) or not model_config.get('sentiment_vals'):\n",
    "        signals.append(ControlSignal(CONTROL_ACTIONS.ABORT, CONTROL_FLAGS.MISSING_REQUIRED,\n",
    "                        f\"Provided `slava_config` is missing required configuration - [MODEL][sentiment_vals]\"))\n",
    "        return signals, None\n",
    "            \n",
    "    slava_sentiment_vals = slava_config_data['MODEL']['sentiment_vals']\n",
    "    \n",
    "\n",
    "    def validateModel(model_name, model_obj):\n",
    "        if not model_obj:\n",
    "            return False\n",
    "        features_accessor = next((x for x in MODEL_NUM_FEATURES if hasattr(model_obj, x[0])), None)\n",
    "        if not features_accessor:\n",
    "            return False\n",
    "        num_model_features = features_accessor[1](model_obj)\n",
    "        if num_model_features != num_vectorizer_features: # Model must be associated with the vectorizer!\n",
    "            signals.append(ControlSignal(CONTROL_ACTIONS.WARNING, CONTROL_FLAGS.FILE_MANAGEMENT,\n",
    "                                            (f'Mismatched number of features between model [{model_name}]' +\n",
    "                                                f'and the provided vectorizer.\\n# Model Features: {num_model_features}\\n' +\n",
    "                                                f'# Vectorizer Features: {num_vectorizer_features}')))\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "\n",
    "    if isinstance(slava_models, (tuple, list)):\n",
    "        for model_info in slava_models:\n",
    "            if isinstance(model_info, (tuple, list)):\n",
    "                model_name, model_def = model_info[0], model_info[1]  \n",
    "            else:\n",
    "                model_name, model_def = model_info['name'], { k: v for k, v in model_info.items() if k != 'name' }\n",
    "            \n",
    "            if 'protocol' not in model_name:\n",
    "                valid_obj, model = validateObject(obj=model_def, obj_protocol=searchParams([f'{model_name}_protocol'], slava_models), \n",
    "                                        allowed_types=MODEL_DEF_TYPES, \n",
    "                                        err_signal=ControlSignal(CONTROL_ACTIONS.INFO, CONTROL_FLAGS.IMPORT_EXCEPTION,\n",
    "                                            f'Could not import predictive model: {model_def}'))\n",
    "                if valid_obj == INVALID:\n",
    "                    continue\n",
    "                if validateModel(model_name, model):\n",
    "                    existing_models[model_name] = model\n",
    "\n",
    "    elif isinstance(slava_models, dict):\n",
    "        for model_name, model_def in slava_models.items():\n",
    "            if 'protocol' not in model_name:\n",
    "                valid_obj, model = validateObject(obj=model_def, obj_protocol=searchParams([f'{model_name}_protocol'], slava_models), \n",
    "                                        allowed_types=MODEL_DEF_TYPES, \n",
    "                                        err_signal=ControlSignal(CONTROL_ACTIONS.INFO, CONTROL_FLAGS.IMPORT_EXCEPTION,\n",
    "                                            f'Could not import predictive model: {model_def}'))\n",
    "                if valid_obj == INVALID:\n",
    "                    continue\n",
    "                if validateModel(model_name, model):\n",
    "                    existing_models[model_name] = model\n",
    "    \n",
    "    if not existing_models:\n",
    "        signals.append(ControlSignal(CONTROL_ACTIONS.ABORT, CONTROL_FLAGS.MISSING_REQUIRED),\n",
    "                        'Could not import Slava models which are required for inferences.')\n",
    "        return signals, None\n",
    "\n",
    "    X = sentiment_df[x_col]\n",
    "    y = sentiment_df[y_col]\n",
    "\n",
    "\n",
    "    # Transform text using vectorizer\n",
    "    X_test = vectorizer.transform(X.reset_index()[x_col]).toarray()\n",
    "    X_test_fit = vectorizer.fit_transform(X.reset_index()[x_col]).toarray()\n",
    "\n",
    "    # Collect features\n",
    "    feature_names = vectorizer.get_feature_names_out() \n",
    "\n",
    "    # Load linearSVC\n",
    "    if (linear_svc_path := kwargs.get('linear_svc')):\n",
    "        linear_svc = load(linear_svc_path)\n",
    "        existing_models['linear_svc'] = (linear_svc, {}) # Place holder for performance metrics\n",
    "\n",
    "    # Load MultinomialNB\n",
    "    if (multi_nb_path := kwargs.get('multi_nb')):\n",
    "        existing_models['multi_nb'] = (load(multi_nb_path), {}) # Place holder for performance metrics\n",
    "\n",
    "    model_params = {\n",
    "        'x_test': X_test,\n",
    "        'x_test_fit': X_test_fit,\n",
    "        'y_test': y,\n",
    "        'features': feature_names\n",
    "    }\n",
    "    \n",
    "    return signals, (sentiment_df, existing_models, model_params, slava_sentiment_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `model` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(sentiment_df, existing_models, model_params, sentiment_vals, **kwargs):\n",
    "    signals = []\n",
    "    \n",
    "    # Map sentiment encodings\n",
    "    p1_sentiment_encoding = sentiment_vals['value_mapping']\n",
    "\n",
    "    sentiment_codes = np.array([int(x) for x in p1_sentiment_encoding.keys()])\n",
    "    sentiment_labels = np.array(list(p1_sentiment_encoding.values()))\n",
    "\n",
    "    map_offset = np.abs(sentiment_codes.min())\n",
    "    mapping_arr = np.zeros(len(sentiment_codes), dtype=sentiment_labels.dtype)\n",
    "    mapping_arr[sentiment_codes+map_offset] = sentiment_labels\n",
    "\n",
    "    model_predictions = {}\n",
    "    for model_name, model in existing_models.items():\n",
    "        X_test = model_params['x_test']\n",
    "\n",
    "        # Generate prediction\n",
    "        inferences = model.predict(X_test)\n",
    "        predictions_arr = mapping_arr[inferences]\n",
    "\n",
    "        # Build df from predictions\n",
    "        zipped_data = zip(sentiment_df['clean_tweet'], sentiment_df['sentiment_val'], predictions_arr)\n",
    "        inferences_df = pd.DataFrame(zipped_data, columns=['clean_tweet', 'pred_sentiment_val', 'pred_sentiment'])\n",
    "        \n",
    "        model_predictions[model_name] = inferences_df\n",
    "\n",
    "    return signals, (model_predictions, mapping_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `inspect` function\n",
    "Used to calculate each model's performance\n",
    "\n",
    "#### **Cluster** model validation\n",
    "1. Internal validation\n",
    "    - Typically will combine cohesion (within each cluster) and separation (between different clusters)\n",
    "    - Compute the validation score of each cluster and then uses weights in the aggregation to produce a final score for the entire model\n",
    "\n",
    "2. External validation\n",
    "    - Necessary to have *True* cluster labels\n",
    "    - Measure the statistical similarity between the *True* cluster labels and the actual values\n",
    "\n",
    "#### **Classification** metrics\n",
    "1. Classification Accuracy:\n",
    "    - The ratio of correct predictions to the total number of predicitions\n",
    "    - Popular but flawed (often misused/misinterpreted); there are two criteria to meet for this calculation:\n",
    "        1. Equal number of observations in all classes\n",
    "        2. All predictions and prediction errors are equally important\n",
    "2. Log Loss\n",
    "    - Evaluates the predictions of probabilities of membership to a given class\n",
    "    - Can be seen as a measure of confidence for a prediction algorithm\n",
    "3. Area Under ROC Curve\n",
    "    - Designed for binary classification problems\n",
    "4. Confusion Matrix\n",
    "    - Provides the accuracy of a model which has two or more classes\n",
    "    - Presents the predicitions in relation to the accuracy outcome\n",
    "5. Classificaiton Report\n",
    "    - `scikit-learn`'s function to summarize a classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small evaluation functions to be used by `inspect`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MetricReports:\n",
    "\n",
    "    def getTests():\n",
    "        return {\n",
    "            'cross_val': MetricReports.crossValidation,\n",
    "            'confusion': MetricReports.confusionMatrix,\n",
    "            'classification': MetricReports.classificationReport\n",
    "        }\n",
    "\n",
    "    def execute(model, features, y_test, y_pred, **kwargs):\n",
    "        return [\n",
    "            MetricReports.crossValidation(model, features, y_pred, **kwargs),\n",
    "            MetricReports.confusionMatrix(y_test, y_pred),\n",
    "            MetricReports.classificationReport(y_test, y_pred)\n",
    "        ]\n",
    "\n",
    "    ## Metric Functions ##\n",
    "\n",
    "    def crossValidation(model, features, y_pred, scoring=None, kfold=5):\n",
    "        res = []\n",
    "        if not scoring:\n",
    "            scoring = ['accuracy']\n",
    "        for score in scoring:\n",
    "            res.append({\n",
    "                'name': f'CV Classification - {score}',\n",
    "                'result': cross_val_score(estimator=model,\n",
    "                                            X=features, \n",
    "                                            y=y_pred, \n",
    "                                            scoring=score, \n",
    "                                            cv=kfold)\n",
    "            })\n",
    "        return res\n",
    "\n",
    "    def confusionMatrix(y_test, y_pred):\n",
    "        ''' FIXME: This might not be a valid metric... not sure if it can handle unlabeled data\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Confusion Matrix',\n",
    "            'result': metrics.confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "        }\n",
    "\n",
    "    def classificationReport(y_test, y_pred):\n",
    "        ''' FIXME: This might not be a valid metric... not sure if it can handle unlabeled data\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Classification Report',\n",
    "            'result': metrics.classification_report(y_true=y_test, y_pred=y_pred, output_dict=True)\n",
    "        }\n",
    "\n",
    "\n",
    "## Best suited for unsupervised clustering algorithms ##\n",
    "\n",
    "class MetricScores:\n",
    "\n",
    "    def getTests():\n",
    "        return {\n",
    "            'silhouette': MetricScores.silhouetteScore,\n",
    "            'calinski_harabaz': MetricScores.calinskiHarabaz,\n",
    "            'dabies_bouldin': MetricScores.dabiesBouldin,\n",
    "            'mean_acc': MetricScores.meanAccuracy\n",
    "        }\n",
    "\n",
    "    def execute(model, features, y_pred):\n",
    "        return [\n",
    "            MetricScores.silhouetteScore(features, y_pred),\n",
    "            MetricScores.calinskiHarabaz(features, y_pred),\n",
    "            MetricScores.dabiesBouldin(features, y_pred),\n",
    "            MetricScores.meanAccuracy(model, features, y_pred)\n",
    "        ]\n",
    "\n",
    "    ## Metric Functions ##\n",
    "\n",
    "    def silhouetteScore(features, y_pred):\n",
    "        ''' Attempts to describe how similar a datapoint is to other datapoints in its cluster, \n",
    "        relative to datapoints not in its cluster (aggregated over all datapoints to get the score for \n",
    "        an overall clustering). It evaluates how ‘distinct’ the clusters are in space\n",
    "        It's bounded between -1 and 1. Closer to -1 suggests incorrect clustering, while \n",
    "        closer to +1 shows that each cluster is very dense.\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Silhouette Score',\n",
    "            'result': metrics.silhouette_score(X=features, labels=y_pred)\n",
    "        }\n",
    "\n",
    "    def calinskiHarabaz(features, y_pred):\n",
    "        ''' A ratio of the variance of a datapoint compared to points in other clusters, \n",
    "        against the variance compared to points within its cluster. This score is not bounded.\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Calinski Harabaz Index',\n",
    "            'result': metrics.calinski_harabasz_score(X=features, labels=y_pred)\n",
    "        }\n",
    "\n",
    "    def dabiesBouldin(features, y_pred):\n",
    "        ''' The average similarity measure of each cluster with its most similar cluster, \n",
    "        where similarity is the ratio of within-cluster distances to between-cluster distances. \n",
    "        Thus, clusters which are farther apart and less dispersed will result in a better score.\n",
    "        The minimum score is zero, with lower values indicating better clustering.\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Davies-Bouldin Index',\n",
    "            'result': metrics.davies_bouldin_score(X=features, labels=y_pred)\n",
    "        }\n",
    "\n",
    "    def meanAccuracy(model, features, y_pred):\n",
    "        '''\n",
    "        '''\n",
    "        return {\n",
    "            'name': 'Mean Accuracy',\n",
    "            'result': model.score(X=features, y=y_pred)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `evaluate` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(sentiment_df, prediction_dfs, existing_models, model_params, **kwargs):\n",
    "    signals = []\n",
    "\n",
    "    # Set up variables\n",
    "    cv_scores = kwargs.get('cv_scores', ['accuracy'])\n",
    "    # crossVal_accuracies = list(zip(cv_scores, [[]]*len(cv_scores)))\n",
    "    crossVal_accuracies = defaultdict(list)\n",
    "\n",
    "    test_names = list(MetricReports.getTests().keys()) + list(MetricScores.getTests().keys())\n",
    "    metric_results = { m: { k: [] for k in test_names } for m in existing_models.keys() }\n",
    "    cv_dfs = { m: {} for m in existing_models.keys() }\n",
    "\n",
    "     # y_test = tweets_df['sentiment_val']\n",
    "    y_test = model_params['y_test']\n",
    "    X_test = model_params['x_test']\n",
    "    X_test_fit = model_params['x_test_fit']\n",
    "\n",
    "    ## Begin evaluations\n",
    "    for model_name, model in existing_models.items():\n",
    "        y_pred = prediction_dfs[model_name]['pred_sentiment_val']\n",
    "\n",
    "        metric_reports = MetricReports.execute(model=model, \n",
    "                                                features=X_test, \n",
    "                                                y_test=y_test, \n",
    "                                                y_pred=y_pred, \n",
    "                                                scoring=cv_scores, \n",
    "                                                kfold=kwargs.get('kfold'))\n",
    "        metric_scores = MetricScores.execute(model=model, \n",
    "                                                features=X_test, \n",
    "                                                y_pred=y_pred)\n",
    "\n",
    "        metric_results[model_name] = metric_reports + metric_scores\n",
    "\n",
    "        # Aggregate cross validation results\n",
    "        for results in metric_reports:\n",
    "            iterable = [results] if not isinstance(results, (list, tuple)) else results\n",
    "            for res in iterable:\n",
    "                if 'CV' in res['name']:\n",
    "                    score_name = res['name'].split(' ')[-1]\n",
    "                    indexed_acc = [(model_name, idx, acc) for idx, acc in enumerate(res['result'])]\n",
    "                    crossVal_df = pd.DataFrame(indexed_acc, columns=['model_name', 'fold_idx', score_name])\n",
    "                    crossVal_accuracies[score_name].append(crossVal_df)\n",
    "        \n",
    "        # Combine cross val results by scoring type\n",
    "        for score_type, models in crossVal_accuracies.items():\n",
    "            cv_dfs[model_name][score_type] = pd.concat(models)\n",
    "\n",
    "    # Create a dict of Sentiment_val\n",
    "    sentiment_id_df = sentiment_df[['sentiment_val', 'sentiment']].drop_duplicates().sort_values('sentiment_val')\n",
    "    sentiment_to_id = dict(sentiment_id_df.values)\n",
    "\n",
    "    sentiment_maps = {\n",
    "        'sentiment_id': sentiment_id_df.to_json(),\n",
    "        'sentiment_to': sentiment_to_id\n",
    "    }\n",
    "\n",
    "    return signals, (metric_results, cv_dfs, sentiment_maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define `load` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(prediction_dfs, results={}, cv_dfs={}, destinations={}, exec_config=None):\n",
    "    signals = []\n",
    "\n",
    "    # Export the execution config\n",
    "    if (config_loc := destinations.get('config')):\n",
    "        with open(config_loc, 'w') as f:\n",
    "            json.dump(exec_config, f)\n",
    "    \n",
    "    def loadGroup(group_name, group_data):\n",
    "        if not group_name in destinations:\n",
    "            return\n",
    "        group_destinations = destinations[group_name]\n",
    "        export_locs = { name: path for name, path in group_destinations.items()\n",
    "                                        if (name in group_data and group_data.get(name) is not None) }\n",
    "        for name, path in export_locs.items():\n",
    "            export_obj = group_data[name]\n",
    "            if isinstance(export_obj, pd.DataFrame): # Expected origin: `prediction_dfs`\n",
    "                export_obj.to_csv(path)\n",
    "            elif isinstance(export_obj, dict): # Expected origin: `cv_dfs`\n",
    "                aggregated_obj = pd.concat(export_obj.values(), keys=export_obj.keys())\n",
    "                aggregated_obj.to_csv(path)\n",
    "            else:\n",
    "                print(path)\n",
    "                print(export_obj)\n",
    "                print('\\n\\n')\n",
    "                dump(export_obj, path) # Expected origin: `results` or `built_models`\n",
    "    \n",
    "    for name, data in zip(['predictions', 'metrics', 'cross_validations'], \n",
    "                            [prediction_dfs, results, cv_dfs]):\n",
    "        if data:\n",
    "            loadGroup(name, data)\n",
    "            \n",
    "    # Save current notebook for import\n",
    "    if (notebook_dest := destinations.get('notebook')):\n",
    "        \n",
    "        !jupyter nbconvert --output {notebook_dest} --to script pipeline_1.ipynb\n",
    "\n",
    "        # Get rid of excess\n",
    "        with open(notebook_dest + '.py', 'r+') as fp:\n",
    "            lines = fp.readlines()\n",
    "            fp.seek(0)\n",
    "            fp.truncate()\n",
    "            cell_markers = set([])\n",
    "            term_index = len(lines) - 1\n",
    "            for i, line in enumerate(lines):\n",
    "                if '# Execute `pipeline`' in line:\n",
    "                    term_index = i\n",
    "                    break\n",
    "                elif '# In[' in line:\n",
    "                    cell_markers.add(i)\n",
    "\n",
    "            fp.writelines([l for i, l in enumerate(lines[:term_index]) if i not in cell_markers])\n",
    "    return signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build `pipeline` function using above processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline2(default_configs, user_configs=None, extract_args={}, model_args={}, evaluate_args={}, load_args={}, log_level=None, **kwargs):\n",
    "\n",
    "    parsing_signals, valid_p1_params = buildConfig(dflt_configs=default_configs, usr_configs=user_configs,\n",
    "                                                    extract_config=extract_args, evaluate_config=evaluate_args,\n",
    "                                                    model_config=model_args, load_config=load_args,\n",
    "                                                    nested_params='PIPE_1')\n",
    "    processSignals(signals=parsing_signals, log_level=log_level) # Process error/info signals\n",
    "\n",
    "    p2_user_config = user_configs[0] if hasattr(user_configs, '__iter__') else user_configs\n",
    "    p2_dflt_config = default_configs[0] if hasattr(default_configs, '__iter__') else default_configs\n",
    "    parsing_signals, valid_p2_params = buildConfig(dflt_configs=p2_dflt_config, usr_configs=p2_user_config, \n",
    "                                                    extract_config=extract_args, evaluate_config=evaluate_args,\n",
    "                                                    model_config=model_args, load_config=load_args,\n",
    "                                                    excluded_params='PIPE_1')\n",
    "    processSignals(signals=parsing_signals, log_level=LOG_LEVEL)\n",
    "\n",
    "    pipeline_stages = ['EXTRACT', 'MODEL', 'EVALUATE', 'LOAD']\n",
    "    p2_extract_params, p2_model_params, p2_evaluate_params, p2_load_params = itemgetter(*pipeline_stages)(valid_p2_params)\n",
    "\n",
    "    # Store run-specific information\n",
    "    execution_config = defaultdict(dict)\n",
    "    print('\\n--- Executing Pipeline 2 ---\\n')\n",
    "\n",
    "    ## Extract (import)\n",
    "    print('[Pipeline 2] Stage 1: Extracting...')\n",
    "    extract_signals, extracted_data = extract(**p2_extract_params)\n",
    "    processSignals(signals=extract_signals, generated_files=p2_load_params, log_level=log_level) # Process error/info signals\n",
    "    \n",
    "    if not extracted_data:\n",
    "        print('\\n*** Aborting Pipeline 2 ***')\n",
    "        print('Will attempt to use Pipeline 1 to produce required data.\\n')\n",
    "\n",
    "        # Transform dataset using Pipeline 1 to produce a sentiment distribution of the data\n",
    "        sentiment_df, word_vecs, models = pipeline1(default_configs=valid_p1_params)\n",
    "        extract_signals, extracted_data = extract(sentiment_dataset=sentiment_df, slava_vectorizer=models.get('vectorizer'),\n",
    "                                                    slava_models={k:v for k, v in models.items() if k != 'vectorizer'} \n",
    "                                                    **{ k: v for k, v in p2_extract_params.items() if k != 'vectorizer' })\n",
    "        processSignals(signals=extract_signals, generated_files=p2_load_params, log_level=log_level) # Process error/info signals\n",
    "    \n",
    "    sentiment_df, existing_models, model_params, slava_sentiment_vals = extracted_data\n",
    "    print('[Pipeline 2] Completed Stage 1.', end='\\n\\n')\n",
    "\n",
    "    ## Model\n",
    "    print('[Pipeline 2] Stage 2: Modeling...')\n",
    "    model_signals, model_data = model(sentiment_df=sentiment_df, existing_models=existing_models,\n",
    "                                        model_params=model_params, sentiment_vals=slava_sentiment_vals,\n",
    "                                        **p2_model_params)\n",
    "    processSignals(signals=model_signals, generated_files=p2_load_params, log_level=log_level) # Process error/info signals\n",
    "    model_predictions, mapping_arr = model_data\n",
    "    execution_config['mapping_array'] = mapping_arr.tolist()\n",
    "    print('[Pipeline 2] Completed Stage 2.', end='\\n\\n')\n",
    "\n",
    "    ## Evaluation\n",
    "    print('[Pipeline 2] Stage 3: Evaluating...')\n",
    "    evaluation_signals, evaluation_data = evaluate(sentiment_df=sentiment_df, prediction_dfs=model_predictions,\n",
    "                                                    existing_models=existing_models, model_params=model_params,\n",
    "                                                    **p2_evaluate_params)\n",
    "    processSignals(signals=evaluation_signals, generated_files=p2_load_params, log_level=log_level) # Process error/info signals\n",
    "    metric_results, cross_val_dfs, sentiment_maps = evaluation_data\n",
    "    execution_config['sentiment_maps'] = sentiment_maps\n",
    "    print('[Pipeline 2] Completed Stage 3.', end='\\n\\n')\n",
    "    valid_p2_params['PIPE_1'] = valid_p1_params\n",
    "    mergeDicts(execution_config, valid_p2_params)\n",
    "\n",
    "    ## Loading (export)\n",
    "    print('[Pipeline 2] Stage 4: Loading...')\n",
    "    load_signals = load(prediction_dfs=model_predictions, results=metric_results, \n",
    "                        cv_dfs=cross_val_dfs, destinations=p2_load_params, exec_config=execution_config)\n",
    "    processSignals(signals=load_signals, generated_files=p2_load_params, log_level=log_level) # Process error/info signals\n",
    "    print('[Pipeline 2] Completed Stage 4.', end='\\n\\n')\n",
    "    print('[Pipeline 2] <done>')\n",
    "    \n",
    "    return model_predictions, metric_results, cross_val_dfs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Executing Pipeline 2 ---\n",
      "\n",
      "[Pipeline 2] Stage 1: Extracting...\n",
      "[Warning] Able to continue execution but be aware - Could not interpret a required config value. Missing sentiment dataset definition.\n",
      "\n",
      "*** Aborting Pipeline 2 ***\n",
      "Will attempt to use Pipeline 1 to produce required data.\n",
      "\n",
      "\n",
      "--- Executing Pipeline 1. ---\n",
      "\n",
      "Stage 1: Extracting...\n",
      "Importing data from \"../../data/russia_vs_ukraine_tweets.csv\"...\n",
      "Completed Stage 1.\n",
      "\n",
      "Stage 2: Transforming...\n",
      "** Top 25 Similar Word Vectors By Cluster **\n",
      "\n",
      "Unique Terms from Clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster 0</th>\n",
       "      <th>Cluster 1</th>\n",
       "      <th>Cluster 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arm_force</td>\n",
       "      <td>remind</td>\n",
       "      <td>sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year_ago</td>\n",
       "      <td>highly</td>\n",
       "      <td>australian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>appear</td>\n",
       "      <td>link</td>\n",
       "      <td>acknowledge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>align</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>alternative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>transform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>behalf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster 0 Cluster 1    Cluster 2\n",
       "0  arm_force    remind        sport\n",
       "1   year_ago    highly   australian\n",
       "2     appear      link  acknowledge\n",
       "3                          addition\n",
       "4                             align\n",
       "5                       alternative\n",
       "6                         transform\n",
       "7                            behalf"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Terms from Clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster 0 (baseline)</th>\n",
       "      <th>Cluster 1 relative to Cluster 0</th>\n",
       "      <th>Cluster 2 relative to Cluster 0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>argentina</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>-2.384508e-07</td>\n",
       "      <td>2.354700e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equation</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>-4.769017e-07</td>\n",
       "      <td>2.771988e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>economic</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>-1.192254e-07</td>\n",
       "      <td>9.999961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fee</th>\n",
       "      <td>0.999865</td>\n",
       "      <td>-8.345779e-07</td>\n",
       "      <td>9.999961e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>0.999865</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.950826e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tactic</th>\n",
       "      <td>0.999865</td>\n",
       "      <td>4.172889e-07</td>\n",
       "      <td>9.999964e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarrass</th>\n",
       "      <td>0.999865</td>\n",
       "      <td>-5.365144e-07</td>\n",
       "      <td>4.143079e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surely</th>\n",
       "      <td>0.999865</td>\n",
       "      <td>1.192254e-07</td>\n",
       "      <td>9.999968e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>significant</th>\n",
       "      <td>0.999866</td>\n",
       "      <td>2.324896e-06</td>\n",
       "      <td>9.999977e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <td>0.999866</td>\n",
       "      <td>-4.172889e-07</td>\n",
       "      <td>-2.235474e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fascism</th>\n",
       "      <td>0.999866</td>\n",
       "      <td>-1.192254e-07</td>\n",
       "      <td>-3.278696e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>update</th>\n",
       "      <td>0.999867</td>\n",
       "      <td>2.384508e-07</td>\n",
       "      <td>3.845016e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maybe</th>\n",
       "      <td>0.999867</td>\n",
       "      <td>-8.345779e-07</td>\n",
       "      <td>5.573783e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>narrative</th>\n",
       "      <td>0.999868</td>\n",
       "      <td>-1.192254e-07</td>\n",
       "      <td>4.262305e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <td>0.999868</td>\n",
       "      <td>1.073029e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>front</th>\n",
       "      <td>0.999869</td>\n",
       "      <td>1.430705e-06</td>\n",
       "      <td>7.779451e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mali</th>\n",
       "      <td>0.999870</td>\n",
       "      <td>2.384508e-07</td>\n",
       "      <td>1.818186e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>another</th>\n",
       "      <td>0.999870</td>\n",
       "      <td>1.490318e-06</td>\n",
       "      <td>8.137127e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dy</th>\n",
       "      <td>0.999872</td>\n",
       "      <td>-1.788381e-07</td>\n",
       "      <td>2.116249e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>letter</th>\n",
       "      <td>0.999873</td>\n",
       "      <td>8.941906e-07</td>\n",
       "      <td>2.414312e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tv</th>\n",
       "      <td>0.999875</td>\n",
       "      <td>8.345779e-07</td>\n",
       "      <td>2.831601e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favor</th>\n",
       "      <td>0.999879</td>\n",
       "      <td>-1.132641e-06</td>\n",
       "      <td>-4.619981e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Cluster 0 (baseline)  Cluster 1 relative to Cluster 0  \\\n",
       "term                                                                 \n",
       "argentina                0.000000                    -1.000000e+00   \n",
       "former                   0.999864                    -2.384508e-07   \n",
       "equation                 0.999864                    -4.769017e-07   \n",
       "economic                 0.999864                    -1.192254e-07   \n",
       "fee                      0.999865                    -8.345779e-07   \n",
       "none                     0.999865                     1.000000e+00   \n",
       "tactic                   0.999865                     4.172889e-07   \n",
       "embarrass                0.999865                    -5.365144e-07   \n",
       "surely                   0.999865                     1.192254e-07   \n",
       "significant              0.999866                     2.324896e-06   \n",
       "correct                  0.999866                    -4.172889e-07   \n",
       "fascism                  0.999866                    -1.192254e-07   \n",
       "update                   0.999867                     2.384508e-07   \n",
       "maybe                    0.999867                    -8.345779e-07   \n",
       "narrative                0.999868                    -1.192254e-07   \n",
       "period                   0.999868                     1.073029e-06   \n",
       "front                    0.999869                     1.430705e-06   \n",
       "mali                     0.999870                     2.384508e-07   \n",
       "another                  0.999870                     1.490318e-06   \n",
       "dy                       0.999872                    -1.788381e-07   \n",
       "letter                   0.999873                     8.941906e-07   \n",
       "tv                       0.999875                     8.345779e-07   \n",
       "favor                    0.999879                    -1.132641e-06   \n",
       "\n",
       "             Cluster 2 relative to Cluster 0  \n",
       "term                                          \n",
       "argentina                      -1.000000e+00  \n",
       "former                          2.354700e-06  \n",
       "equation                        2.771988e-06  \n",
       "economic                        9.999961e-01  \n",
       "fee                             9.999961e-01  \n",
       "none                            2.950826e-06  \n",
       "tactic                          9.999964e-01  \n",
       "embarrass                       4.143079e-06  \n",
       "surely                          9.999968e-01  \n",
       "significant                     9.999977e-01  \n",
       "correct                        -2.235474e-06  \n",
       "fascism                        -3.278696e-07  \n",
       "update                          3.845016e-06  \n",
       "maybe                           5.573783e-06  \n",
       "narrative                       4.262305e-06  \n",
       "period                          1.000000e+00  \n",
       "front                           7.779451e-06  \n",
       "mali                            1.818186e-06  \n",
       "another                         8.137127e-06  \n",
       "dy                              2.116249e-06  \n",
       "letter                          2.414312e-06  \n",
       "tv                              2.831601e-06  \n",
       "favor                          -4.619981e-06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label each cluster: -1 = negative, 0 = neutral, 1 = positive (\"r\" for new samples, \"q\" to exit)\n",
      "\n",
      "\n",
      "Generating next 25 samples...\n",
      "\n",
      "Unique Terms from Clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster 0</th>\n",
       "      <th>Cluster 1</th>\n",
       "      <th>Cluster 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>align</td>\n",
       "      <td>impoverish</td>\n",
       "      <td>hello</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>allegedly</td>\n",
       "      <td>none</td>\n",
       "      <td>peace_talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>argentina</td>\n",
       "      <td></td>\n",
       "      <td>insane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remind</td>\n",
       "      <td></td>\n",
       "      <td>elon_musk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bunker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>chain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>see_happen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>neocon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>independent_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>period</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Cluster 0   Cluster 1            Cluster 2\n",
       "0       align  impoverish                hello\n",
       "1   allegedly        none           peace_talk\n",
       "2   argentina                           insane\n",
       "3      remind                        elon_musk\n",
       "4                                       bunker\n",
       "5                                        chain\n",
       "6                                   see_happen\n",
       "7                                       neocon\n",
       "8                                         ball\n",
       "9                          independent_country\n",
       "10                                         fee\n",
       "11                                      period"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicate Terms from Clusters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster 0 (baseline)</th>\n",
       "      <th>Cluster 1 relative to Cluster 0</th>\n",
       "      <th>Cluster 2 relative to Cluster 0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>throughout</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.999985e-01</td>\n",
       "      <td>-9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arm_force</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.999999e-01</td>\n",
       "      <td>-9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appear</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_ago</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.999999e-01</td>\n",
       "      <td>-9.999997e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kremlin</th>\n",
       "      <td>0.999861</td>\n",
       "      <td>-2.682575e-07</td>\n",
       "      <td>9.538081e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reform</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>-3.874830e-07</td>\n",
       "      <td>1.848003e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accord</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>8.941915e-08</td>\n",
       "      <td>9.999977e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compliance</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>-2.086447e-07</td>\n",
       "      <td>1.013421e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deserve</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>-5.067085e-07</td>\n",
       "      <td>9.999979e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>australian</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>1.490319e-07</td>\n",
       "      <td>9.999979e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ukrainerussianwar</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>-1.520126e-06</td>\n",
       "      <td>9.999979e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transform</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>-2.056641e-06</td>\n",
       "      <td>9.999979e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carve</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>-3.874830e-07</td>\n",
       "      <td>9.999980e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>-1.490319e-07</td>\n",
       "      <td>9.999981e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recognize</th>\n",
       "      <td>0.999862</td>\n",
       "      <td>5.067085e-07</td>\n",
       "      <td>2.146068e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addition</th>\n",
       "      <td>0.999863</td>\n",
       "      <td>4.470958e-07</td>\n",
       "      <td>9.999986e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>humiliate</th>\n",
       "      <td>0.999863</td>\n",
       "      <td>2.682575e-07</td>\n",
       "      <td>9.999989e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>javelin</th>\n",
       "      <td>0.999863</td>\n",
       "      <td>-2.980638e-08</td>\n",
       "      <td>2.205681e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spirit</th>\n",
       "      <td>0.999863</td>\n",
       "      <td>-5.663213e-07</td>\n",
       "      <td>3.934459e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acknowledge</th>\n",
       "      <td>0.999863</td>\n",
       "      <td>5.067085e-07</td>\n",
       "      <td>9.999992e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>2.682575e-07</td>\n",
       "      <td>9.999998e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>4.709428e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>behalf</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>8.941915e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>7.451596e-07</td>\n",
       "      <td>2.742198e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highly</th>\n",
       "      <td>0.999864</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.888267e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Cluster 0 (baseline)  Cluster 1 relative to Cluster 0  \\\n",
       "term                                                                       \n",
       "throughout                     0.000000                    -9.999985e-01   \n",
       "arm_force                      0.000000                    -9.999999e-01   \n",
       "appear                         0.000000                    -1.000000e+00   \n",
       "year_ago                       0.000000                    -9.999999e-01   \n",
       "kremlin                        0.999861                    -2.682575e-07   \n",
       "reform                         0.999862                    -3.874830e-07   \n",
       "accord                         0.999862                     8.941915e-08   \n",
       "compliance                     0.999862                    -2.086447e-07   \n",
       "deserve                        0.999862                    -5.067085e-07   \n",
       "australian                     0.999862                     1.490319e-07   \n",
       "ukrainerussianwar              0.999862                    -1.520126e-06   \n",
       "transform                      0.999862                    -2.056641e-06   \n",
       "carve                          0.999862                    -3.874830e-07   \n",
       "ever                           0.999862                    -1.490319e-07   \n",
       "recognize                      0.999862                     5.067085e-07   \n",
       "addition                       0.999863                     4.470958e-07   \n",
       "humiliate                      0.999863                     2.682575e-07   \n",
       "javelin                        0.999863                    -2.980638e-08   \n",
       "spirit                         0.999863                    -5.663213e-07   \n",
       "acknowledge                    0.999863                     5.067085e-07   \n",
       "value                          0.999864                     2.682575e-07   \n",
       "link                           0.999864                     9.999998e-01   \n",
       "behalf                         0.999864                     8.941915e-08   \n",
       "wind                           0.999864                     7.451596e-07   \n",
       "highly                         0.999864                     1.000000e+00   \n",
       "\n",
       "                   Cluster 2 relative to Cluster 0  \n",
       "term                                                \n",
       "throughout                           -9.999998e-01  \n",
       "arm_force                            -9.999999e-01  \n",
       "appear                               -1.000000e+00  \n",
       "year_ago                             -9.999997e-01  \n",
       "kremlin                               9.538081e-07  \n",
       "reform                                1.848003e-06  \n",
       "accord                                9.999977e-01  \n",
       "compliance                            1.013421e-06  \n",
       "deserve                               9.999979e-01  \n",
       "australian                            9.999979e-01  \n",
       "ukrainerussianwar                     9.999979e-01  \n",
       "transform                             9.999979e-01  \n",
       "carve                                 9.999980e-01  \n",
       "ever                                  9.999981e-01  \n",
       "recognize                             2.146068e-06  \n",
       "addition                              9.999986e-01  \n",
       "humiliate                             9.999989e-01  \n",
       "javelin                               2.205681e-06  \n",
       "spirit                                3.934459e-06  \n",
       "acknowledge                           9.999992e-01  \n",
       "value                                 9.999998e-01  \n",
       "link                                  4.709428e-06  \n",
       "behalf                                1.000000e+00  \n",
       "wind                                  2.742198e-06  \n",
       "highly                                4.888267e-06  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state: []\n",
      "Setting cluster: 0\n",
      "Set cluster 0 to 0 (neutral)\n",
      "Set cluster 1 to -1 (negative)\n",
      "Set cluster 2 to 1(positive)\n",
      "\n",
      "Applying sentiment mapping...\n",
      "\n",
      "Calculated Sentiment Distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neutral     8177\n",
       "positive    1188\n",
       "negative     547\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Aborting execution - User-caused. Distribution was unsatisfactory.\n",
      "\n",
      "Terminating Process...\n"
     ]
    },
    {
     "ename": "JupyterExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mJupyterExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "PIPE1_USER_CONFIG = '../pipeline_1/config/user_config.json'\n",
    "PIPE2_USER_CONFIG = './config/user_config.json'\n",
    "\n",
    "PIPE1_DFLT_CONFIG = '../pipeline_1/config/default_config.json'\n",
    "PIPE2_DFLT_CONFIG= './config/default_config.json'\n",
    "LOG_LEVEL = CONTROL_ACTIONS.WARNING\n",
    "\n",
    "model_predictions, metric_results, cross_val_dfs = pipeline2(default_configs=[PIPE2_DFLT_CONFIG, PIPE1_DFLT_CONFIG],\n",
    "                                                            user_configs=[PIPE2_USER_CONFIG, PIPE1_USER_CONFIG],\n",
    "                                                            log_level=LOG_LEVEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import get_scorer_names\n",
    "get_scorer_names()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10d883baf2d2c020187d16fb74e1bc85e676b385dd78044a08a209b4abcafece"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
