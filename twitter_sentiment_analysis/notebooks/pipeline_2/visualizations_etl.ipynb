{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL of Pipeline 2 Data for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare constants\n",
    "\n",
    "MODEL_DIR_NAMES = ['linear_svc', 'multi_nb']\n",
    "MODEL_FILE_NAMES = ['linearSVC', 'multinomialNB']\n",
    "VIZ_2_DATA_LOC = '../../../visualizations/part2/data' # UGLYYYY, want to reference based on root (dev/)\n",
    "\n",
    "\n",
    "MODEL_NAMES = list(zip(MODEL_DIR_NAMES, MODEL_FILE_NAMES))\n",
    "# Metrics\n",
    "METRIC_LOCS = { d_name: f'./data/metrics/{d_name}/{f_name}_metrics.joblib' for d_name, f_name in MODEL_NAMES } \n",
    "TRANSFORMED_METRIC_LOCS = { d_name: f'{VIZ_2_DATA_LOC}/metrics/{d_name}/{f_name}_metrics.json' for d_name, f_name in MODEL_NAMES}\n",
    "# CLEAN_WORDS_OUTPUT_LOC = VIZ_1_DATA_LOC + 'cleaned_words.csv'\n",
    "\n",
    "# CV_Scores\n",
    "CV_LOCS = { d_name: f'./data/cv_scores/{d_name}/{f_name}_cv_scores.joblib' for d_name, f_name in MODEL_NAMES } \n",
    "TRANSFORMED_CV_LOCS = { d_name: f'{VIZ_2_DATA_LOC}/cv_scores/{d_name}/{f_name}_cv_scores.json' for d_name, f_name in MODEL_NAMES}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `metrics/` transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import defined metrics\n",
    "raw_metrics = { name: load(path) for name, path in METRIC_LOCS.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CV Classification - accuracy': (array([0.95298281, 0.95500506, 0.9580172 , 0.95599393, 0.9549823 ]),\n",
       "  array([0.94034378, 0.94034378, 0.94334851, 0.94638341, 0.94284269])),\n",
       " 'Confusion Matrix': (array([[ 384,    0,    0],\n",
       "         [   0,  295,    0],\n",
       "         [   0,    0, 9208]]),\n",
       "  array([[ 384,    0,    0],\n",
       "         [   0,  295,    0],\n",
       "         [   0,    0, 9208]])),\n",
       " 'Classification Report': ({'-1': {'precision': 1.0,\n",
       "    'recall': 1.0,\n",
       "    'f1-score': 1.0,\n",
       "    'support': 384},\n",
       "   '0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 295},\n",
       "   '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 9208},\n",
       "   'accuracy': 1.0,\n",
       "   'macro avg': {'precision': 1.0,\n",
       "    'recall': 1.0,\n",
       "    'f1-score': 1.0,\n",
       "    'support': 9887},\n",
       "   'weighted avg': {'precision': 1.0,\n",
       "    'recall': 1.0,\n",
       "    'f1-score': 1.0,\n",
       "    'support': 9887}},\n",
       "  {'-1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 384},\n",
       "   '0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 295},\n",
       "   '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 9208},\n",
       "   'accuracy': 1.0,\n",
       "   'macro avg': {'precision': 1.0,\n",
       "    'recall': 1.0,\n",
       "    'f1-score': 1.0,\n",
       "    'support': 9887},\n",
       "   'weighted avg': {'precision': 1.0,\n",
       "    'recall': 1.0,\n",
       "    'f1-score': 1.0,\n",
       "    'support': 9887}}),\n",
       " 'Silhouette Score': (-0.036127309997831904, -0.036127309997831904),\n",
       " 'Calinski Harabaz Index': (16.97261914177201, 16.97261914177201),\n",
       " 'Davies-Bouldin Index': (9.588753845132262, 9.588753845132262),\n",
       " 'Mean Accuracy': (0.03964802265601294, 0.038636593506624864)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format imported metrics\n",
    "flattened_metrics = {}\n",
    "for model_name, metrics in raw_metrics.items():\n",
    "    model_out = {}\n",
    "    for metric in metrics:\n",
    "        if isinstance(metric, list):\n",
    "            metric = metric[0]\n",
    "        if not isinstance(metric, dict):\n",
    "            model_out = metric\n",
    "        else:\n",
    "            model_out[metric.get('name')] = metric.get('result')\n",
    "    flattened_metrics[model_name] = model_out\n",
    "\n",
    "grouped_metrics = list(zip(*[x.items() for x in flattened_metrics.values()]))\n",
    "metrics_lookup = { z[0][0]: z[1] for z in [list(zip(*a)) for a in grouped_metrics] }\n",
    "\n",
    "metrics_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CV Classification - accuracy': (('linear_svc',\n",
       "   array([0.95298281, 0.95500506, 0.9580172 , 0.95599393, 0.9549823 ])),\n",
       "  ('multi_nb',\n",
       "   array([0.94034378, 0.94034378, 0.94334851, 0.94638341, 0.94284269]))),\n",
       " 'Confusion Matrix': (('linear_svc',\n",
       "   array([[ 384,    0,    0],\n",
       "          [   0,  295,    0],\n",
       "          [   0,    0, 9208]])),\n",
       "  ('multi_nb',\n",
       "   array([[ 384,    0,    0],\n",
       "          [   0,  295,    0],\n",
       "          [   0,    0, 9208]]))),\n",
       " 'Classification Report': (('linear_svc',\n",
       "   {'-1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 384},\n",
       "    '0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 295},\n",
       "    '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 9208},\n",
       "    'accuracy': 1.0,\n",
       "    'macro avg': {'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1-score': 1.0,\n",
       "     'support': 9887},\n",
       "    'weighted avg': {'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1-score': 1.0,\n",
       "     'support': 9887}}),\n",
       "  ('multi_nb',\n",
       "   {'-1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 384},\n",
       "    '0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 295},\n",
       "    '1': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 9208},\n",
       "    'accuracy': 1.0,\n",
       "    'macro avg': {'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1-score': 1.0,\n",
       "     'support': 9887},\n",
       "    'weighted avg': {'precision': 1.0,\n",
       "     'recall': 1.0,\n",
       "     'f1-score': 1.0,\n",
       "     'support': 9887}})),\n",
       " 'Silhouette Score': (('linear_svc', -0.036127309997831904),\n",
       "  ('multi_nb', -0.036127309997831904)),\n",
       " 'Calinski Harabaz Index': (('linear_svc', 16.97261914177201),\n",
       "  ('multi_nb', 16.97261914177201)),\n",
       " 'Davies-Bouldin Index': (('linear_svc', 9.588753845132262),\n",
       "  ('multi_nb', 9.588753845132262)),\n",
       " 'Mean Accuracy': (('linear_svc', 0.03964802265601294),\n",
       "  ('multi_nb', 0.038636593506624864))}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_label = lambda metric_name: tuple([(model_name, val) for model_name, val in zip(raw_metrics.keys(), metrics_lookup[metric_name])])\n",
    "labeled_metrics = { k: assign_label(k) for k in metrics_lookup }\n",
    "labeled_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `cv_scores/` transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "44",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/visualizations_etl.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/visualizations_etl.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39m# Import cross validation scores\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/visualizations_etl.ipynb#ch0000008?line=1'>2</a>\u001b[0m raw_cv_scores \u001b[39m=\u001b[39m { name: load(path) \u001b[39mfor\u001b[39;00m name, path \u001b[39min\u001b[39;00m CV_LOCS\u001b[39m.\u001b[39mitems() }\n",
      "\u001b[1;32m/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/visualizations_etl.ipynb Cell 9\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/visualizations_etl.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39m# Import cross validation scores\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/petergish/Cerebrum/Corpus_Callosum/Neocortex/School/Undergrad/USF/Computer_Science/Data_Visualization/FinalProject/dev/twitter_sentiment_analysis/notebooks/pipeline_2/visualizations_etl.ipynb#ch0000008?line=1'>2</a>\u001b[0m raw_cv_scores \u001b[39m=\u001b[39m { name: load(path) \u001b[39mfor\u001b[39;00m name, path \u001b[39min\u001b[39;00m CV_LOCS\u001b[39m.\u001b[39mitems() }\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/joblib/numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    582\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    583\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    584\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 587\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[1;32m    588\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/joblib/numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    504\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[1;32m    508\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[1;32m    512\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nlp/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39m)\n\u001b[1;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyError\u001b[0m: 44"
     ]
    }
   ],
   "source": [
    "# Import cross validation scores\n",
    "raw_cv_scores = { name: load(path) for name, path in CV_LOCS.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10d883baf2d2c020187d16fb74e1bc85e676b385dd78044a08a209b4abcafece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
